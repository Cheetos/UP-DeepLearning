{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8d1c8b",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "For this example we will use the *California Housing* dataset. The target variable is the median house value in a block group, while the exploratory variables contains properties from houses in block groups, such as, the hosue age, the average number of bedrooms, the average number of rooms, and so on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "253b1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a20b7",
   "metadata": {},
   "source": [
    "First, we load the data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5fed3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a929a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308049ea",
   "metadata": {},
   "source": [
    "The `data` property contains only the exploratory variables (without the target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65e167d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f72bf3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.526\n",
       "1        3.585\n",
       "2        3.521\n",
       "3        3.413\n",
       "4        3.422\n",
       "         ...  \n",
       "20635    0.781\n",
       "20636    0.771\n",
       "20637    0.923\n",
       "20638    0.847\n",
       "20639    0.894\n",
       "Name: MedHouseVal, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446db278",
   "metadata": {},
   "source": [
    "## Get theTraining, Validation, and Test sets\n",
    "\n",
    "Here we will scale our data with the `StandardScaler`, so all the features have mean 0 and variance 1. \n",
    "\n",
    "**Note: Do not fit the test nor the validation sets when using the `StandardCaler`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0f68178",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2030b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73243539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(3870, 8)\n",
      "(5160, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb175b",
   "metadata": {},
   "source": [
    "## Create a Builder Function for the Model\n",
    "\n",
    "In order to use cross validation methods from `scikit-learn` we need to use a wrapper and pass the model we will use for training. Here we will define a function that creates and compiles a neural network, with the following parameters:\n",
    "\n",
    "* **n_hidden.** The number of hidden layers\n",
    "* **n_neurons.** The number of neurons on each hidden layer\n",
    "* **learning_rate.** The learning rate for the gradient descent algorithm.\n",
    "* **input_shape.** The shape of the input layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64bac316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c0d8e",
   "metadata": {},
   "source": [
    "Now we create a Keras Regressor wrapper and pass the builder function as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bd8b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "keras_reg = KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cef0ff",
   "metadata": {},
   "source": [
    "## Training and Evaluating\n",
    "\n",
    "Now we can train our neural network with the default parameters using the `fit` method. We need to specify the number of epochs, and we can use a large number since we are adding an *Early Stopping* condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71592344",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9409a00b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 1.1586 - val_loss: 0.6815\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 401us/step - loss: 0.6188 - val_loss: 0.5841\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.5402 - val_loss: 0.5334\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 400us/step - loss: 0.5002 - val_loss: 0.5073\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 408us/step - loss: 0.4807 - val_loss: 0.4903\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 406us/step - loss: 0.4667 - val_loss: 0.4825\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.4508 - val_loss: 0.4651\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.4426 - val_loss: 0.4600\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.4369 - val_loss: 0.4544\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 406us/step - loss: 0.4324 - val_loss: 0.4494\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.4274 - val_loss: 0.4464\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.4227 - val_loss: 0.4441\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.4213 - val_loss: 0.4398\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.4168 - val_loss: 0.4381\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.4141 - val_loss: 0.4373\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.4115 - val_loss: 0.4331\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 402us/step - loss: 0.4085 - val_loss: 0.4330\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.4065 - val_loss: 0.4286\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.4031 - val_loss: 0.4295\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.4025 - val_loss: 0.4271\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3998 - val_loss: 0.4257\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3983 - val_loss: 0.4232\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3950 - val_loss: 0.4238\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3964 - val_loss: 0.4243\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3945 - val_loss: 0.4231\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.3966 - val_loss: 0.4271\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3930 - val_loss: 0.4250\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.4008 - val_loss: 0.4249\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3948 - val_loss: 0.4219\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3944 - val_loss: 0.4217\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3886 - val_loss: 0.4217\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3881 - val_loss: 0.4198\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3840 - val_loss: 0.4145\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3794 - val_loss: 0.4130\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3778 - val_loss: 0.4122\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3787 - val_loss: 0.4100\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3754 - val_loss: 0.4111\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3761 - val_loss: 0.4063\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3731 - val_loss: 0.4138\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3724 - val_loss: 0.4115\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3707 - val_loss: 0.4069\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3706 - val_loss: 0.4067\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3690 - val_loss: 0.4045\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3684 - val_loss: 0.4036\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3673 - val_loss: 0.4026\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3666 - val_loss: 0.4017\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3653 - val_loss: 0.4013\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3655 - val_loss: 0.4088\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 400us/step - loss: 0.3642 - val_loss: 0.4070\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.3650 - val_loss: 0.4036\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3671 - val_loss: 0.4008\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3612 - val_loss: 0.4045\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3605 - val_loss: 0.4042\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3617 - val_loss: 0.4011\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.3678 - val_loss: 0.4041\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 424us/step - loss: 0.3631 - val_loss: 0.4066\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.3652 - val_loss: 0.4097\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3645 - val_loss: 0.3996\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 398us/step - loss: 0.3636 - val_loss: 0.4013\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3560 - val_loss: 0.3942\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3538 - val_loss: 0.3933\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3533 - val_loss: 0.3983\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3532 - val_loss: 0.3910\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3523 - val_loss: 0.3916\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3517 - val_loss: 0.3905\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3499 - val_loss: 0.3910\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3510 - val_loss: 0.3903\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.3482 - val_loss: 0.3925\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 399us/step - loss: 0.3486 - val_loss: 0.3940\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.3484 - val_loss: 0.3923\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3476 - val_loss: 0.3873\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.3472 - val_loss: 0.3878\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3458 - val_loss: 0.3876\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3487 - val_loss: 0.3875\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 394us/step - loss: 0.3442 - val_loss: 0.3862\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3439 - val_loss: 0.3851\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 403us/step - loss: 0.3436 - val_loss: 0.3980\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 398us/step - loss: 0.3437 - val_loss: 0.3841\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.3432 - val_loss: 0.3829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3414 - val_loss: 0.3810\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3404 - val_loss: 0.3854\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3445 - val_loss: 0.3904\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3403 - val_loss: 0.3836\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3419 - val_loss: 0.3814\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3382 - val_loss: 0.3971\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 385us/step - loss: 0.3406 - val_loss: 0.3886\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3372 - val_loss: 0.3805\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3383 - val_loss: 0.3835\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3439 - val_loss: 0.3887\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 406us/step - loss: 0.3475 - val_loss: 0.3892\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3517 - val_loss: 0.3871\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3478 - val_loss: 0.3833\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 404us/step - loss: 0.3394 - val_loss: 0.3774\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 406us/step - loss: 0.3361 - val_loss: 0.3760\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3343 - val_loss: 0.3771\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 409us/step - loss: 0.3345 - val_loss: 0.3889\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3346 - val_loss: 0.3742\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 411us/step - loss: 0.3354 - val_loss: 0.3728\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 405us/step - loss: 0.3324 - val_loss: 0.3782\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3333 - val_loss: 0.3721\n"
     ]
    }
   ],
   "source": [
    "history = keras_reg.fit(X_train, \n",
    "                        y_train, \n",
    "                        epochs=100, \n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a16a3",
   "metadata": {},
   "source": [
    "As we did before, we can get the score from the test set, as well as predictions for new observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdc681f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 286us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7392659805784185"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8a8035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "20046    0.47700\n",
      "3024     0.45800\n",
      "15663    5.00001\n",
      "Name: MedHouseVal, dtype: float64\n",
      "[0.39385572 1.3463789  3.783409  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/yn9wyn852cvd2npsc01_7fn40000gn/T/ipykernel_18285/2593341646.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_new = y_test[:3]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_new = y_test[:3]\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "\n",
    "print(y_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291142dd",
   "metadata": {},
   "source": [
    "With the `history_` property, we obtain the record of the loss value for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9672ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGyCAYAAACiMq99AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcrElEQVR4nO3dd5hU5eH28e/07R22wAJLk4642EDsgGDXWKIRTSQJsQVJjBpT1NeEFDUmMdhijTUm6M9EFBYLImpEXIqAgLSlbGF7n3reP84W1u27s7PF+3Nd55qZM2fmPDPPLtz7nKdYDMMwEBEREREJAWtvF0BEREREvjkUPkVEREQkZBQ+RURERCRkFD5FREREJGQUPkVEREQkZBQ+RURERCRkFD5FREREJGQUPkVEREQkZBQ+RURERCRkFD5FREREJGQ6HT4/+OADzj//fNLS0rBYLLz++uvtvmbNmjVkZmYSFhbGyJEjefTRR7tSVhERERHp5zodPquqqpg6dSoPP/xwh47fu3cv8+fPZ9asWWRnZ/Pzn/+cW265hX//+9+dLqyIiIiI9G8WwzCMLr/YYuG1117joosuavWY22+/nTfeeIPt27c37Fu0aBGbNm3i448/7uqpRURERKQfsvf0CT7++GPmzJnTZN/cuXN58skn8Xq9OByOZq9xu9243e6Gx4FAgOLiYhITE7FYLD1dZBERERHpJMMwqKioIC0tDau19YvrPR4+8/LySE5ObrIvOTkZn89HYWEhqampzV6zdOlS7rnnnp4umoiIiIgE2YEDBxg6dGirz/d4+ASatVbWX+lvrRXzzjvvZMmSJQ2Py8rKGDZsGHv37iU6OrrnClrH6/Xy8PL3eW6XjclDYnjuu9N7/JwSfF6vl/fee48zzjijxRZ26R9UjwOD6rH/Ux0ODD1ZjxUVFWRkZLSb1Xo8fKakpJCXl9dkX0FBAXa7ncTExBZf43K5cLlczfYnJCQQExPTI+U8mtfrJSoiAqvLBs6IVsspfZvX6yUiwqw//UPZf6keBwbVY/+nOhwYerIe69+vvS6SPT7P58knn0xWVlaTfatWrWL69Ol9+ofXXvfNeHyB3i2IiIiIyADS6fBZWVnJxo0b2bhxI2BOpbRx40ZycnIA85L5ggULGo5ftGgR+/fvZ8mSJWzfvp2nnnqKJ598kp/+9KfB+QQ9xG41uwZ4/AqfIiIiIsHS6cvun332GWeccUbD4/q+mddeey3PPPMMubm5DUEUICMjgxUrVnDrrbfyt7/9jbS0NP7yl79w6aWXBqH4Pcde12Kslk8RERGR4Ol0+Dz99NNpa2rQZ555ptm+0047jc8//7yzp+pVNl12FxER6TWBQACPx9PbxRhwvF4vdrud2tpa/H5/p17rcDiw2WzdLkNIRrv3R2r5FBER6R0ej4e9e/cSCOj/4GAzDIOUlBQOHDjQpbnT4+LiSElJ6da86wqfragfcORWn08REZGQMQyD3NxcbDYb6enpbU5WLp0XCASorKwkKiqqU9+tYRhUV1dTUFAA0OI87R2l8NmKo1s+DcPQykoiIiIh4PP5qK6uJi0tjYiIiN4uzoBT350hLCys08E+PDwcMKfMHDx4cJcvwevPiVbYj/pmvP7W+7iKiIhI8NT3Q3Q6nb1cEmlJ/R8EXq+3y++h8NkK+1ENnZpuSUREJLR0xbFvCka9KHy24uiWTw06EhEREQkOhc9WWC1gt5rpXuFTRERE2nL66aezePHi3i5Gv6Dw2QZnXfOnwqeIiIhIcCh8tsFZN9O8p5OTsIqIiIhIyxQ+21Df8ulWy6eIiIh0UElJCQsWLCA+Pp6IiAjmzZvHrl27Gp7fv38/559/PvHx8URGRjJx4kRWrFjR8Nqrr76aQYMGER4ezpgxY3j66ad766P0CM3z2QanTX0+RUREepNhGNR4e+cKZLjD1qXR3ddddx27du3ijTfeICYmhttvv5358+ezbds2HA4HN954Ix6Phw8++IDIyEi2bdtGVFQUAL/85S/Ztm0bb731FklJSXz11VfU1NQE+6P1KoXPNqjPp4iISO+q8fqZ8KuVvXLubffOJcLZuahUHzrXrVvHjBkzAHjhhRdIT0/n9ddf57LLLiMnJ4dLL72UyZMnAzBy5MiG1+fk5DBt2jSmT58OwIgRI4LzYfoQXXZvQ2OfT4VPERERad/27dux2+2ceOKJDfsSExM55phj2L59OwC33HIL9913HzNnzuTXv/41mzdvbjj2Rz/6ES+//DLHHnssP/vZz/joo49C/hl6mlo+26CWTxERkd4V7rCx7d65vXbuzjKMlldFPHqp7oULFzJ37lzefPNNVq1axdKlS3nggQe4+eabmTdvHvv37+fNN99k9erVnHXWWdx4443cf//93fosfYlaPtug8CkiItK7LBYLEU57r2xd6e85YcIEfD4f//vf/xr2FRUVsXPnTsaPH9+wLz09nUWLFrF8+XJ+8pOf8MQTTzQ8N2jQIK677jqef/55HnroIR5//PHufYl9jFo+26DL7iIiItIZY8aM4cILL+T73/8+jz32GNHR0dxxxx0MGTKECy+8EIDFixczb948xo4dS0lJCe+++25DMP3Vr35FZmYmEydOxO1289///rdJaB0I1PLZBoemWhIREZFOevrpp8nMzOS8887j5JNPxjAMVqxYgcPhAMDv93PjjTcyfvx4zjnnHI455hiWLVsGgNPp5M4772TKlCmceuqp2Gw2Xn755d78OEGnls82NLR8KnyKiIhIG95///2G+/Hx8Tz33HOtHvvXv/611ed+8Ytf8Itf/CKYRetz1PLZBvX5FBEREQkuhc82NIRP9fkUERERCQqFzzbosruIiIhIcCl8tkGX3UVERESCS+GzDQ1ru+uyu4iIiEhQKHy2QS2fIiIiIsGl8NmG+j6fmudTREREJDgUPtuglk8RERGR4FL4bIOmWhIREREJLoXPNjROteTv5ZKIiIjIQDZixAgeeuihDh1rsVh4/fXXe7Q8PUnhsw267C4iIiISXAqfbWho+dRldxEREZGgUPhsg1o+RUREpD2PPfYYQ4YMIRBomhcuuOACrr32Wnbv3s2FF15IcnIyUVFRHH/88axevTpo59+yZQtnnnkm4eHhJCYm8oMf/IDKysqG599//31OOOEEIiMjSUhIYO7cuezfvx+ATZs2ccYZZxAdHU1MTAyZmZl89tlnQStbSxQ+26DwKSIi0ssMAzxVvbMZRoeKeNlll1FYWMh7773XsK+kpISVK1dy9dVXU1lZyfz581m9ejXZ2dnMnTuX888/n5ycnG5/PdXV1ZxzzjnEx8ezfv16Xn31VVavXs1NN90EgM/n46KLLuK0005j8+bNrFu3juuuuw6LxVxI5+qrr2bo0KGsX7+eDRs2cMcdd+BwOLpdrrbYe/Td+znN8ykiItLLvNXw27TeOffPD4Mzst3DEhISOOecc3jxxRc566yzAHj11VdJSEjgrLPOwmazMXXq1Ibj77vvPl577TXeeOONhpDYVS+88AI1NTU899xzREaaZX344Yc5//zz+f3vf4/D4aCsrIzzzjuPUaNGEQgEGDJkCDExMQDk5ORw2223MW7cOADGjBnTrfJ0hFo+2+C0a3lNERERad/VV1/Nv//9b9xuN2CGwiuvvBKbzUZVVRU/+9nPmDBhAnFxcURFRfHll18GpeVz+/btTJ06tSF4AsycOZNAIMCOHTtISEjguuuua2ht/ctf/kJeXl7DsUuWLGHhwoWcffbZ/O53v2P37t3dLlN71PLZhsaplhQ+RUREeoUjwmyB7K1zd9D5559PIBDgzTff5Pjjj2ft2rU8+OCDANx2222sXLmS+++/n9GjRxMeHs63vvUtPB5Pt4toGEbDJfSvq9//9NNPc8stt/D222/zz3/+k1/+8pesXLmSGTNmcPfdd3PVVVfx5ptv8tZbb/HrX/+al19+mYsvvrjbZWuNwmcb1OdTRESkl1ksHbr03dvCw8O55JJLeOGFF/jqq68YO3YsmZmZAKxdu5brrruuIdBVVlayb9++oJx3woQJPPvss1RVVTW0fq5btw6r1crYsWMbjps2bRrTpk3j9ttv56STTuKll15ixowZAIwdO5axY8dy66238u1vf5unn366R8OnLru3QVMtiYiISEddffXVvPnmmzz11FN85zvfadg/evRoli9fzsaNG9m0aRNXXXVVs5Hx3TlnWFgY1157LV988QXvvfceN998M9dccw3Jycns3buXO++8k48//pj9+/ezatUqvvrqK8aNG0dNTQ033XQT77//Pvv372fdunWsX7+e8ePHB6VsrVHLZxvU8ikiIiIddeaZZ5KQkMCOHTu46qqrGvb/6U9/4nvf+x4zZswgKSmJ22+/nfLy8qCcMyIigpUrV/LjH/+Y448/noiICC699NKGS/4RERF8+eWXPPvssxQVFZGamsr3v/99fvjDHxIIBCgqKmLBggXk5+eTlJTEJZdcwj333BOUsrVG4bMNCp8iIiLSUTabjcOHm/dPHTFiBO+++26TfTfeeGOTx525DG98bQqoyZMnN3v/esnJybz22msNjwOBAOXl5VitVux2Oy+99FKHzxssuuzehvrL7r6AQSDQsbm+RERERKR1Cp9tqG/5BPX7FBERkZ73wgsvEBUV1eI2ceLE3i5eUOiyexvqWz7BnGg+zGHrxdKIiIjIQHfBBRdw4okntvhcT688FCoKn21w2BrnzVK/TxEREelp0dHRREdH93YxepQuu7fBYrE0DjrSZXcRERGRblP4bIdLqxyJiIiE3NdHdEvfEIz5SXXZvR1OuxXcCp8iIiKh4HA4sFgsHDlyhEGDBrW6dKR0TSAQwOPxUFtbi9Xa8TZIwzDweDwcOXIEq9WK0+nschkUPtuhuT5FRERCx2azMXToUA4ePBi0JSilkWEY1NTUEB4e3qVgHxERwbBhwzoVXL9O4bMdjX0+/b1cEhERkW+GqKgoxowZg9fr7e2iDDher5cPPviAU089tdOj5202G3a7vdut0Qqf7aifbsmtlk8REZGQsdls2Gya4jDYbDYbPp+PsLCwXpu6SQOO2qHL7iIiIiLBo/DZDoVPERERkeBR+GxH/WV3zfMpIiIi0n0Kn+1Qy6eIiIhI8Ch8tsOl8CkiIiISNAqf7ahv+dRodxEREZHuU/hsh1PLa4qIiIgEjcJnOxonmVf4FBEREekuhc926LK7iIiISPAofLbDWbe6gi67i4iIiHSfwmc7NNWSiIiISPAofLajsc+nv5dLIiIiItL/KXy2Q/N8ioiIiASPwmc7NNWSiIiISPAofLZDUy2JiIiIBI/CZzs04EhEREQkeBQ+21F/2V3zfIqIiIh0X5fC57Jly8jIyCAsLIzMzEzWrl3b5vEvvPACU6dOJSIigtTUVL773e9SVFTUpQKHmlo+RURERIKn0+HzlVdeYfHixdx1111kZ2cza9Ys5s2bR05OTovHf/jhhyxYsIDrr7+erVu38uqrr7J+/XoWLlzY7cKHgvp8ioiIiARPp8Pngw8+yPXXX8/ChQsZP348Dz30EOnp6TzyyCMtHv/JJ58wYsQIbrnlFjIyMjjllFP44Q9/yGeffdbtwoeCWj5FREREgsfemYM9Hg8bNmzgjjvuaLJ/zpw5fPTRRy2+ZsaMGdx1112sWLGCefPmUVBQwL/+9S/OPffcVs/jdrtxu90Nj8vLywHwer14vd7OFLlL6s/h9XqxYYZOt9cfknNL8Bxdj9J/qR4HBtVj/6c6HBh6sh47+p6dCp+FhYX4/X6Sk5Ob7E9OTiYvL6/F18yYMYMXXniBK664gtraWnw+HxdccAF//etfWz3P0qVLueeee5rtX7VqFREREZ0pcrdkZWWxpxzATml5JStWrAjZuSV4srKyersIEgSqx4FB9dj/qQ4Hhp6ox+rq6g4d16nwWc9isTR5bBhGs331tm3bxi233MKvfvUr5s6dS25uLrfddhuLFi3iySefbPE1d955J0uWLGl4XF5eTnp6OnPmzCEmJqYrRe4Ur9dLVlYWs2fP5suCav689X/YXWHMn39aj59bgufoenQ4HL1dHOki1ePAoHrs/1SHA0NP1mP9ler2dCp8JiUlYbPZmrVyFhQUNGsNrbd06VJmzpzJbbfdBsCUKVOIjIxk1qxZ3HfffaSmpjZ7jcvlwuVyNdvvcDhC+gPvcDiICHMC4PUb+mXrp0L9cyM9Q/U4MKge+z/V4cDQE/XY0ffr1IAjp9NJZmZms6barKwsZsyY0eJrqqursVqbnsZmswFmi2lfp+U1RURERIKn06PdlyxZwt///neeeuoptm/fzq233kpOTg6LFi0CzEvmCxYsaDj+/PPPZ/ny5TzyyCPs2bOHdevWccstt3DCCSeQlpYWvE/SQ+pHu7s11ZKIiIhIt3W6z+cVV1xBUVER9957L7m5uUyaNIkVK1YwfPhwAHJzc5vM+XnddddRUVHBww8/zE9+8hPi4uI488wz+f3vfx+8T9GDjp5qqa2+rSIiIiLSvi4NOLrhhhu44YYbWnzumWeeabbv5ptv5uabb+7KqXqdq66LAJj9Pp12hU8RERGRrtLa7u2ob/kErXIkIiIi0l0Kn+1oEj416EhERESkWxQ+22GzWrBZzUvtCp8iIiIi3aPw2QGabklEREQkOBQ+O6BhxLvf38slEREREenfFD47oGGuT7V8ioiIiHSLwmcH6LK7iIiISHAofHaAy67wKSIiIhIMCp8d0NjnU+FTREREpDsUPjvAqZZPERERkaBQ+OwA9fkUERERCQ6Fzw7QZXcRERGR4FD47ABNtSQiIiISHAqfHaDL7iIiIiLBofDZARpwJCIiIhIcCp8doD6fIiIiIsGh8NkBmmReREREJDgUPjvAZbcBCp8iIiIi3aXw2QG67C4iIiISHAqfHaDR7iIiIiLBofDZAZrnU0RERCQ4FD47QFMtiYiIiASHwmcHNFx2V59PERERkW5R+OyAxpZPfy+XRERERKR/U/jsAF12FxEREQkOhc8OcGmqJREREZGgUPjsAE21JCIiIhIcCp8doMvuIiIiIsGh8NkBmudTREREJDgUPjtAUy2JiIiIBIfCZwfosruIiIhIcCh8doDCp4iIiEhwKHx2gKZaEhEREQkOhc8OcNpsgFo+RURERLpL4bMDdNldREREJDgUPjugPnz6AgaBgNHLpRERERHpvxQ+O6A+fIL6fYqIiIh0h8JnS9wVxFTnNDysn+cTwO1V+BQRERHpKntvF6DPqTyC4/7RnI4Fn+86cDhw2CwNT7v9fsDRa8UTERER6c/U8vl1kUkYrhgsGFC8FwCLxaJBRyIiIiJBoPD5dRYLRsIo827xVw27XTaFTxEREZHuUvhsSeJoACxFuxt2OTXRvIiIiEi3KXy2wKgPn0e1fOqyu4iIiEj3KXy2oD58UqTwKSIiIhJMCp8tMBLqL7t/BYY5qbxTfT5FREREuk3hsyUJIzGwYKktheoioLHl060+nyIiIiJdpvDZEkc4Nc5E837hLkCX3UVERESCQeGzFZWuFPNOUV341GV3ERERkW5T+GxFZViqeUctnyIiIiJBo/DZisaWT3PEu0vzfIqIiIh0m8JnKypdavkUERERCTaFz1ZUhtW1fJbsBb9PfT5FREREgkDhsxU1jgQMezgEfFC6X8trioiIiASBwmdrLFZIGGXeL9zVOM+nWj5FREREukzhsw1GYl34LNqF02YDdNldREREpDsUPtvQsMb7US2fCp8iIiIiXafw2YaG8Fn01VF9Pv29WCIRERGR/k3hsy1H9fl0qeVTREREpNsUPttgJI4x71QVEGlUAQqfIiIiIt2h8NkWVzREJQMwyJ0DaKolERERke5Q+GxPXetnQm1d+FTLp4iIiEiXKXy2J8kcdBRXvR/QPJ8iIiIi3aHw2Z66ls/YuvCplk8RERGRrlP4bE9SffjcB8DhsppeLIyIiIhI/6bw2Z66uT4jKvZjIcCB4hrKary9XCgRERGR/knhsz1xw8HqwOKrYVqsOd3Sl7nlvVwoERERkf6pS+Fz2bJlZGRkEBYWRmZmJmvXrm3zeLfbzV133cXw4cNxuVyMGjWKp556qksFDjmbHRIyADglrhSAbQqfIiIiIl1i7+wLXnnlFRYvXsyyZcuYOXMmjz32GPPmzWPbtm0MGzasxddcfvnl5Ofn8+STTzJ69GgKCgrw+XzdLnzIJI6Bwp0cG3EESGfbYYVPERERka7odPh88MEHuf7661m4cCEADz30ECtXruSRRx5h6dKlzY5/++23WbNmDXv27CEhIQGAESNGdK/UoZY0GnbAaGsuAFsVPkVERES6pFPh0+PxsGHDBu64444m++fMmcNHH33U4mveeOMNpk+fzh/+8Af+8Y9/EBkZyQUXXMD/+3//j/Dw8BZf43a7cbvdDY/Ly82w5/V68Xp7frBP/Tnqby1xI7HTuMrRroIKqmrcOO3qMtuXfb0epX9SPQ4Mqsf+T3U4MPRkPXb0PTsVPgsLC/H7/SQnJzfZn5ycTF5eXouv2bNnDx9++CFhYWG89tprFBYWcsMNN1BcXNxqv8+lS5dyzz33NNu/atUqIiIiOlPkbsnKygIgofIIswAjfyvhNoMaPzz72tsMiQxZUaQb6utR+jfV48Cgeuz/VIcDQ0/UY3V1dYeO6/RldwCLxdLksWEYzfbVCwQCWCwWXnjhBWJjYwHz0v23vvUt/va3v7XY+nnnnXeyZMmShsfl5eWkp6czZ84cYmJiulLkTvF6vWRlZTF79mwcDgdUnwh/uo8IbzHTh0SwNqeGxNFTmT9tSI+XRbquWT1Kv6R6HBhUj/2f6nBg6Ml6rL9S3Z5Ohc+kpCRsNluzVs6CgoJmraH1UlNTGTJkSEPwBBg/fjyGYXDw4EHGjBnT7DUulwuXy9Vsv8PhCOkPfMP5YlMgPB5qSpiZWM7aHAc78qv1y9dPhPrnRnqG6nFgUD32f6rDgaEn6rGj79epTotOp5PMzMxmTbVZWVnMmDGjxdfMnDmTw4cPU1lZ2bBv586dWK1Whg4d2pnT9666ZTanhh8BYFtuWW+WRkRERKRf6vSImSVLlvD3v/+dp556iu3bt3PrrbeSk5PDokWLAPOS+YIFCxqOv+qqq0hMTOS73/0u27Zt44MPPuC2227je9/7XqsDjvqkupWORtWNeN92uBzDMHqzRCIiIiL9Tqf7fF5xxRUUFRVx7733kpuby6RJk1ixYgXDhw8HIDc3l5ycnIbjo6KiyMrK4uabb2b69OkkJiZy+eWXc9999wXvU4RCkhk+E2tzcNimU17r42BJDekJoRsAJSIiItLfdWnA0Q033MANN9zQ4nPPPPNMs33jxo3r/6PjBo0DwJa7kTGDr2VbbjnbcssVPkVEREQ6QRNVdtTwmWCxQdEuTkky+69qpSMRERGRzlH47KjwOBh2MgBnWDcCWuNdREREpLMUPjtj7BwAxld8DKjlU0RERKSzFD47Y4wZPmPzPyGcWg6V1lBa7enlQomIiIj0HwqfnTFoHMQOw+J3c0HMV4AuvYuIiIh0hsJnZ1gsDZfe54dtAXTpXURERKQzFD47q+7S+3HuTwFDLZ8iIiIinaDw2VkjZoE9jGh3PsdYDqjlU0RERKQTFD47yxkBGacC5pRLXxVU4vb5e7lQIiIiIv2DwmdX1F16n+3YhC9gsCu/spcLJCIiItI/KHx2RV34PJYdxFCpS+8iIiIiHaTw2RXxw2HQOGwEONW6RYOORERERDpI4bOrxswG4Axbtlo+RURERDpI4bOrxswF4HTrJr7MLSUQMHq5QCIiIiJ9n8JnVw07CcMVQ6KlglGeHRwsqentEomIiIj0eQqfXWVzYBl1JgCn2zay9XBZLxdIREREpO9T+OyOulHvZ1qz+WDXkV4ujIiIiEjfp/DZHXWDjiZb9/HJ5m3UejXZvIiIiEhbFD67I2owRtpxAMzyfsTq7fm9XCARERGRvk3hs5ssUy4H4Gb767y5fmcvl0ZERESkb1P47K7p38MbM4JBljIm73uagora3i6RiIiISJ+l8NlddheOefcBcL31Td79+LNeLpCIiIhI36XwGQzjziM/fjoui5eU9b/v7dKIiIiI9FkKn8FgsRBxwe8JGBZO937A3uz3ertEIiIiIn2SwmeQRGdM55NYc8lNx+pfgKHlNkVERES+TuEziPyn/4Iqw8XQqi/wb361t4sjIiIi0ucofAbRSVMn8qz1YgC8K38FXq33LiIiInI0hc8gctislB77Qw4ZiYRV58LHD/d2kURERET6FIXPILtg+ih+770SAGPtn+DIjl4ukYiIiEjfofAZZBPTYtg5aC6fBMZj8VbBC9+CyoLeLpaIiIhIn6DwGWQWi4VLM9P5kefH5NrSoDQHXrwcPFW9XTQRERGRXqfw2QMuPDaNMksMV1b/FK8rHg5nw78XQsDf20UTERER6VUKnz1gcEwYV504jP1GCj/w/gTD5oIdK2Dlz3u7aCIiIiK9SuGzh/zi3AlMSI3hveqRPBj9E3Pn/x6Fj5f1bsFEREREepHCZw8Jc9hYdvVxRLvs/DVvEu8Mu9l8YuXPYeOLWgFJREREvpEUPnvQiKRI/vCtKQBcv/MkDoy6CjDg9R/Bk7Nh79reLaCIiIhIiCl89rB5k1P57swRgIULdp9P2fGLwR4OB9fDs+fBPy42BySJiIiIfAMofIbAnfPGc2x6HCW1BtfsnY37xg1w/EKw2mH3u/D46fDPa6Eiv7eLKiIiItKjFD5DwGm38rerjyMuwsHmg2X86p0iAvPuh5vWw+TLAQtse92ckN5d2dvFFREREekxCp8hMiQunAcvn4rFAq98doDb/70Zf1wGXPoE/PADiEiCvM2w/PuaD1REREQGLIXPEDpzXDIPXDYVqwVe3XCQW17KxuMLQOoU+PZLUD8faNaveruoIiIiIj1C4TPELjluKMuuPg6HzcKbW3JZ9PwGar1+SD8BLqqbA/Tjh2HDM71aThEREZGeoPDZC86ZlMrfrz2eMIeVd78s4LtPr6fS7YPJ34LT61ZBevMnsOf9Xi2niIiISLApfPaS08YO4tnvnkCUy87He4r4zt//R1m1F077mTkIKeCDVxbAkZ29XVQRERGRoFH47EUnjkzkhYUnEhfhYOOBUq59+lOqPH644K+QfiK4y+D5S+CTR6Eir7eLKyIiItJtCp+9bGp6HC//4KSGAPqDf3yG2+KAK1+E+BFQdgDevh0eGAfPnAefPQVVRb1dbBEREZEuUfjsA8alxPD0dccT4bSx7qsibnkpG19YAnz/PTjndzD0BMCAfWvhv7fC/WPghctg6+vgc/d28UVEREQ6TOGzj5g2LJ4nFkzHabOycms+dyzfQiAsHk76ESzMgh9vhrPvgZQpYPhh1yp49Vp44BhY8TPI3dTbH0FERESkXQqffcjM0Un89app2KwW/rXhIPe9uR3DMMwn44fDKYth0Vq46TM4ZQlEp0JNCXz6GDx2KjxyCqz7M5Ts79XPISIiItIahc8+Zu7EFP5w6RQAnlq3l4dW72oMoPWSxsDZv4Zbt8LV/4aJF4PNCflbzAnq/zwFnjgT1v0FSnN64VOIiIiItMze2wWQ5i7NHEp5rZd7/rONP7+zi492F/Lz+eOZNiy+6YFWG4w529yqi2Hra+Ya8fs+hEMbzC3rl5B6rDl6Pm2auSWNMV8rIiIiEmIKn33Ud2dmEDDgjyu/ZP2+Ei5e9hHnT03jZ3OPIT0hovkLIhLg+OvNrbIAtr9hDkja9yHkbjS3eo5ISJ0KKZMgaawZRpPGmpfxLZYQfUIRERH5JlL47MOuPyWD+ZNTeGDVTv79+UH+s+kwK7/I47qZI7jx9NHERjhafmHUYDh+oblV5MHetXA429xyN4G3CnI+MrejOaMgcTQMOxnGzoHhM8Hu6vkPKiIiIt8YCp99XGpsOPdfNpXrZozgtyu289HuIh7/YA/PfbyP+ZNSufz4dE7MSMDSWotldApMuczcAAJ+KNxlBtEj2837hTuheC94KhtbSf/3iBlGR54OY+bA6LMgZohaRkVERKRbFD77iUlDYnlh4Ym8v+MIv3/7S77Mq2B59iGWZx9iRGIEl01P51uZQ0mOCWv7jaw2GDzO3I7m80DJPsj/Ana/A7uyoDIfvvyvuQHYXBA7tG5LN2+jBoMrBlzR4Iqqu42G2GFg04+XiIiINKV00I9YLBbOGDeY048ZRPaBUv65/gD/2XSYfUXV/HHlDh5YtYPjRyQwe0IyZ49PZkRSZMff3O6EQWPNbdIlEAhA3ibYucqcU/TQBvC7oXi3ubXHFQujTofRZ8OosyB2SJc/t4iIiAwcCp/9kMVi4bhh8Rw3LJ5fnjeBN7fk8s/1B/hsfwn/21vM//YWc9+b2xk9OIqzxycze8JgpqXHY7V24pK51do4Ov70282W0YrDUHYQSg+Yt2U55ih7dzm4K8FdYV66rykx16Xf9n/mBjB4AmScZraKWm1gsZqb1QaRg2DUmRCT1jNfmIiIiPQZCp/9XKTLzuXT07l8ejoHiqtZvT2f1dvz+d+eYr4qqOSrgkoeXbOb1NgwzpuSynlT0pgyNLb1PqKtsTvNtebjR7R/bMBv9indlQVfrTZbTQu2mVtbUibDmLkwdi4MyWw6HZTPY4Zcb7U5Kt/WymArERER6dMUPgeQ9IQIvjszg+/OzKCsxsuanUdYvS2fd78sILeslifW7uWJtXsZlhDB+VNTmT85lQmpMZ0Pou2x2mDodHM7406zdXT3u3Doc/B7wAiYS4QG/Ob9IzvMgJq3xdzW3g/hCRCZBLXlUFsGvpqj3t9hjsofdAwMGmfeJo42Q2lEotlq2xu8teak/rFDwNmJLg8iIiLfIAqfA1RsuIMLpqZxwdQ0ar1+3t9xhP9uPsw72wvIKa7mb+/t5m/v7WZofDhzJqQwd2Iy00ckYOvMpfmOikiAyd8yt9ZUFZotpbtWmQOeaorN7eusDgh4zZH6R7a38LwdopIhKhlb5GAmlQawZBeac5oOHgdhse2X1+8zw6631ry1Oc1Q+/XW1kDAXFVq93uw5z3I+QR8teZzUSmQOAoSRppb1GDAUjdbQN13bLGaLckpk8HZwtytIiIiA5DC5zdAmMPGOZNSOGdSCtUeH+9sL+A/mw6zZucRDpbU8NS6vTy1bi8JkU7OHDeYcSnRDI4JY3C0y9xiwohy9fCPSmQSHPttc/P74PDn4HObYTEsxrx1xQAWKD9otpYe+bJu22FOFVVdCAEflB+C8kNYgVEAK1Y1nic6zZxUH8xL+J5qc95TTzV4a8ywGfC18kXGmeWMSDJH9h/OhuqipsfYw833qMwzt/3r2v/sFhsMHg9px0LacWYYdUTU9Y21Ne0j25KIBLMvrYiISD+g8PkNE+G0c/7UNM6fmka1x8faXYWs3JrHO9sLKK7y8K8NB1t8XWy4g1PGJHH2+MGcPnYw8ZHOniukzQ7pJ7T+fNwwcxszu+l+v9dc3akyDyry8ZceZO+G1YyM9mA9ssMcMFW/dbgsLrOrAAbUlppb0VeNzzujYMQpMPIMc07UQceYA65K9kLRHijeY84OUFMChmG+T/1twGcG58p8c4qr/C8g+/mOl+1oEUmNfXLjR5itraPOhJjUrr2fiIhID1H4/AaLcNqZOzGFuRNT8PkDfLqvmDU7j3CopIaCCjdHKtzkl9dS7fFTVuPlzc25vLk5F6sFpg9P4Mzxg5k1JomxydE4bL3Uz/JoNofZ37JuWqeA18vW/GSGz5+P1eGAmtK6VtI95uV5R7h5udsRWXcbYe6zhzVuVqvZN7WmxOwaUHXEbGGtKTH7mw6Zbg7GOlpEgrkNyWy/zIYBFblmf9j6VaiO7KjrG3tUv9j626/3zzUMs6W1utDcDn3W+JzFCiNmwZTLYfz5HetyICIi0sMUPgUAu83KjFFJzBiV1Oy5SrePHXkVvPtlPu9sL+DLvAo+3VfMp/uK+d1b4LRZGZMcxYTUGCakxTAhNYZxKTGtL//ZW8LjYNiJ5tYZVpt5uT0yCRjX7uGdYrGYU0zFpMH487r2HrVlULLfXCSgfsvdZAbRvWvM7b9L4JhzYNz5ED/cHJwVndJ7swb4vZqxQETkG0rhU9oV5bKTOTyezOHx3DZ3HAeKq3n3ywLe+bKA7P0lVLh9bD1cztbD5bCh8XXJMS7GJkczNjmaY5KjGZsSzbiUaMIcttZPJp0XFgupU8ztaCX7YMursPlVKNzRdN5VACzmHKsxdbMEuKLBGd24SpUrGuLSIWGUOXiqrRH8AX9dv9R2BqztXQvv/w72f2gODEscY/bBTRprbimTITq5q9+EiIj0Awqf0mnpCRFcO2ME184YgWEYHCypYevhcrbllrPtcDnbc8s5VFpDfrmb/HI3a3cVNrzWbrVwTEo0U4bGMXVoLFOGxjE2OQp7X7hsP9DEj4BTb4NZP4W8zbD5n3BwPZTnmpf6A16oKjC3johONYNodLLZ2lpdNyNBTYn5OCIRjpkPEy6EjFPB7mp87dGhs15lvrkdvQ/MQVfHzIdx883FCfq6qqLGLhz9lbvC7PKR94X5B0DGrN4ukYgMYF0Kn8uWLeOPf/wjubm5TJw4kYceeohZs9r/x2rdunWcdtppTJo0iY0bN3bl1NLHWCwW0hMiSE+I4JxJKQ37y2u97MqvZFd+BTvyK9iZX8H23AqKqzwNraQvfWoea7daGBIfzrC69xlWt41PjWFEYkTw5yH9prFYIHWqudULBMyR+hV1QbSmxAwgR2+1pWbradFuM2TWH9ua6iLI/oe5uWJg7DnmYKwtr8K+teYxNiccdy2cuMhcBavwKyjcWbftMmcvOPy5ub13H8QNxzrmHDKOVGPdkA8Ol9lf12o3w23cMLNVtjf6sx7OhveWwq6V5uOIRIhNN1uLY4dBQobZ7zdlct/qYuCpNlvCczebXTMOfmZ+70ag8Zhp18Dc35ozTYiIBFmnw+crr7zC4sWLWbZsGTNnzuSxxx5j3rx5bNu2jWHDhrX6urKyMhYsWMBZZ51Ffn5+twotfV9MmKPhUn09wzA4VFrD5oNlbDpYypaDZWw5WEaF28f+omr2F1U3e5/ESCfHDY9n+vB4po+IZ9KQWFx2XbbvNqsVogaZ29cv17ekutgcqFW02xx0FR5nLgQQkWDehseZK1htewO+/K/Zornln+YGdaFzAZxyK8QObXzfrw/KqsiHnW/DjrfMuVNL92Nb/xhTAFqeiMEUOaixe0BsulkeV0zTqbrC4szyOqPa7x7QltxNZujc+dbXvqMic8vd2HS/Pdz8nOknQPqJ5uILkc37VjdRU2rOG1uwFbA0Bm6bw+yDHJEEQ46DmCGtf5aA3wz1uZugYLsZMAu2mwshYDQ/PmYoJI2GPWvMPyD2rIGLlqkVVESCrtPh88EHH+T6669n4cKFADz00EOsXLmSRx55hKVLl7b6uh/+8IdcddVV2Gw2Xn/99S4XWPovi8XC0PgIhsZHMH+yOQVQIGCQX1FLTlE1OcXVHCg2b/cVVbMtt5yiKg9Z2/LJ2mb+wWKzWohy2Ylw2gh32gh32Ihw2oiLcDIuJZrxqTGMS4lmeKJWGAqq+hH8Q6e3fkzUYHO6qfn3m5f3t79hznOadhzMWtI0dLYmOhkyrzU3TxXsfg//zlXk7d1OavIgrEbAnKIq4DPnaS3eW9d14Ii5Hfik/XNYHRAe37jVB1RXTOOtK9psWbW5zNkMbHVdCDa+YIZrMPu4Tr4MTv0ZRCZC6QEoO9B4e2SH+T3UlppdC47uXhCdZob+lMmQMsWc57Vwl/l97Vtrtkq2FBCbfefJZrAdchykTjNbqOtnTcjdZH5HLYlIMs85dLo5Y8PQ6eYANIB96+D1RWZIffY8OOkGOOtXZtcCMGdYqDoCZQfN7yB1avfCvIh843QqfHo8HjZs2MAdd9zRZP+cOXP46KOPWn3d008/ze7du3n++ee577772j2P2+3G7XY3PC4vLwfA6/Xi9Xo7U+QuqT9HKM4lkBRhJykihuPSm17ic/sCbDtczoacUj7PKWVDTgnFVV7Kaszt6+oDKkC4w8roQZE4PVY2v/UlqXHhDI52kRITRkpsGCkxrl67nF9c5eGxD/byymcHGRzt4orjh3LxsWkk9OTcqaGWepy5Ha2zv08WJ4yei3f4mXyWlcXs2bNxOFq4fO2ugOI9WIp3YyneAxW5WNzl5tKs7nIs7jKzT2pNKRa/u/N9Xb/GwIIx8RL8s35qDpiqlzTe3JocHICir7Ac/BTrwfVYDn6KpWhX43yzO99u/TwJIzHSMs2wbNQF7oAf/F4sZQegYBuWynzYscLcWnoPZyRG8mSMwRMgaRzGoLEYSeNabnmtr58hJ8DCNdhW/wrrxn/AJ8swdryFETMES/khKD9sfo91AqnTCJyyBGPM3NYXQqCVf1cNw5xSzKrhB0FlGD3yB4H+bxwYerIeO/qeFsMwOvDntenw4cMMGTKEdevWMWPGjIb9v/3tb3n22WfZsWNHs9fs2rWLU045hbVr1zJ27FjuvvtuXn/99Tb7fN59993cc889zfa/+OKLRET040790i2GAWUeqPWDJ1C3+S14Aub+w9UWDldZyK0Gr9H2P7yRdoPhUQYjog2GR8HwKINwu3mOWj9UeOs3CzYLJLoMEsIgrIUr/jU+OFILR2otVPtgWKTB0Ciwfa0ItX5477CF93KtuP1Nn7RZDI5NNJiRHGBUtBqSeoot4Mbhq8Lpr8Tpq8Thq8QRqMHhr8buN28d/hrsgVqsAS9Ww4fV8GINmLcVYUPZlXw+FeFDulwGu7+GmJoDxNbsJ7Ymh9jq/UTXHqLamURh1DiKosZRFD2OWkd8m+9jC7iJqc4hvno38VV7iKvZh9seTWlERt02gkpXapuBsD2DyzYxLedJwnylTfYbWKh1xOH0VWIzzP9sysLS2ZlyPofjTmj7nIZBXPVe0kr/x5CSTwn3FnMw/mR2plxAZVhal8sqpuSybKYeeIaCmClsSr8Ww9I/gv2g8i0MLt/M3kGzqXYN7u3iSBdVV1dz1VVXUVZWRkxM633Gu/RT+fUWI8MwWmxF8vv9XHXVVdxzzz2MHTu2w+9/5513smTJkobH5eXlpKenM2fOnDY/TLB4vV6y2mppkT7NHzDYV1TN1kOlrFm/mdjU4Ryp9JJfXktBhTkCv8oH20otbCs1X2OxwKAoF6U1Xjy+QKvvHR/hYEhcOKmxYRRVedhXVEVxVfO/9CKcNo4bFscJI8z+ql8cLueRNXsoqTaPnZAazY/PGs2RCjcvrz/IF4fL2VBoYUOhlWEJ4STHhOGyW3HarDjrblNjw7jw2FTGDI7qia+tz+pLv4+RQEq7R3VeAAgDhtZtXeUCYoDWe9931nyo/iG+Hf81F12IHYoRMwSiU7HbnASqjsCnj2L97Eliaw9w/L5lGAkrCUy4CMLjMVyxDd0afP4AB955klHuLVjLcpqcJb3kI4aWfIwx8WL8M39irhTWGwJ+c7GGynwslQXmrd+NEZ2KEV03H29EYrcCfU+ybnga68Y/YzECDC9aQ3pCGP5LnjTrLgh66nfRsmsVtn/9CUvAx6ji9wicsIjAzFu1bHAP6cl/U+uvVLenU+EzKSkJm81GXl5ek/0FBQUkJzefm6+iooLPPvuM7OxsbrrpJgACgQCGYWC321m1ahVnnnlms9e5XC5cLlez/Q6HI6T/+YT6fBIcDmBcmpNRgyKxH97E/PkTmtSjxxdge2452TklZB8oJTunlJziagoqGi8lRrnsJEU5SYxy4fEFOFBSTWm1l5K67YvDTX/BkqJcZCRFEOmyk51TSlmNlw+/KuLDr5qu/T4yKZKfzDmGeZNSsFrNP9i+c3IGmw+W8uL/cnhj02FyimvIKa5p8bM9tnYvmcPjufL4dM6bkka485sz+Eq/j70kNhlOuL7l5+LSYM69MOtW+N/j8MkyLMW7sX34QLND7UBDJwVHhDkbwqRLICoFPvwTlh1vYtm6HOvW12DiRTDhIvC5wVtl9v/1VJl9WJ1RdX2Qk8wgGJFoBly/B3y14K1pvAVzftr6zRFp9l2tyIOiXeZSuYV1t/X9h43W//gEzMFz0almP9uJF8OYOY39YXtLIADv3APrHjIfjz0H9ryPdddKrP+8Cq58CVzB+6O12e9idy7z710Ly79ndiuJGYql/CC2j/+CbfPLcNYv4dirzUF2EnQ98W9qR9+vU+HT6XSSmZlJVlYWF198ccP+rKwsLrzwwmbHx8TEsGXLlib7li1bxrvvvsu//vUvMjIyOnN6kaBw2q1MTY9janoc19XtK6x0c6ikhoRIJ0lRrhZDXUWtl4MlNRworia3rJaESCcZSZEMT4wgOqzxFy4QMNiRX8Gne4v5394iPt1bQqTLxg2nj+LS44a2OKfplKFxTBkax13njuezfSVUe/x4/H48vgBuXwC3N8D6fcW882UBG/aXsGF/Cff+ZxsXTktj+vAEXHYrLocVl92Gy24lwmlnTHJU31j2VAa+8Hg4/XY4+QbIfsGcyqm2rMlmuCs5bBtC8pmLsI+b33Re1G+/aA6y+uAPsP0/sPU1c+sVdYsvRCebwdjmNPvnlh+GygIz5JbuN7etr5lh+Jh5MPESGH1W0/ltAwEzCAe8YLGZLaZWm3nfagtO/xqfG16/Ab74l/n4jLvM+X33r4MXr4S9H8BzF8LVr5qhPVgCAXOqrq2vmYtX1JbDtO+YPwNxHWx7P7gBXrrS/I6OmQ+XPwdfrYaVd0HxbnjjZvj0CTjndzBiZtfK6feZg/0Kd5l/kHhrzCWJ6+9HDoKEkY1b1ODQ9nsKBGDrcnPmiuEnh+68vaxTfT7BnGrpmmuu4dFHH+Xkk0/m8ccf54knnmDr1q0MHz6cO++8k0OHDvHcc8+1+PqO9Pn8uvLycmJjY9vtQxAsXq+XFStWMH/+fLW09GMDsR4Lymt5dcNBXl6fw4FWWkfrRbnszBydyGljB3PaMYMYEtfLrTNdNBDr8Zuow/WYvxXW/dmc2ssZaYY7Z6TZWuqIAE9l47RWVYXmbW2ZGfrsYWYrZP0tNG019VQBhtkCmjjKXF0rcQwkjobEkWYAiEgCWyvtMj4PVOaZMwHsXAlbX4ejuxDUt6z63I2hs02WowKptS6U2iE8FiIHm8EoMqnudlBdi29i4zRnNics/4EZrqx2uOCvcOxVjW9/6HN4/hJzHt/kSXDNa2a46iKvx83H/3qYmfFHsG3/D5S3MP+ZxWa2aM+4pe1p3PK3wTPzzbJlnApXvQqOuu4BPg98+jis+YM5HzCY4fTse2BQB7rwBQJw4H/wxb9h2+vm7AwdVf+zMexkGHmaOVdxT80j7K6A1xaZM2hYrHDJEzD5Wz1zrqP05L+pHc1rne7zecUVV1BUVMS9995Lbm4ukyZNYsWKFQwfPhyA3NxccnJy2nkXEemKwTFh3HjGaH502ig+2l3E8uyDFJS7cfv8DS2kbp+f4ioP5bU+Vm7NZ+VWcxaAMYOjOG3sIM6ekMz04fFaVUr6puSJcMnjPfPehmG2djnCu9a6ZXearXpxw8xQMvtec5L+rcvNIFpx2Owm0PECmaP9/f6mu91ldfOxdpAzGq74B4w6o+n+IcfBdSvgHxdB/hfw5BwzxNWH2PrbqGTzM9mbd3fDUw173oedb2Hf8TanHj1LREOr78XmdGQf/9U8dsur5jbydJh8ubl0buKoxpbX4j1mmWpKzKm+rnypMXiC+T3PuAmmXgnv/QY2PGvO6LBzpTkN2+l3Ng/R1cXm4hR73ocvXmsajMMTYPgMs7yOsLo/ZMLNMlfmmeUp3mNOH+atMleEy9sMnz5mhsK0aZBxGow+23yfYLSMFu6Cl682rxKA2d1j+ffNn9Epl3X//fu4Trd89ga1fEpXfJPrMRAw+OJwGWt2HOH9nUfIzikhcNRvelyEgzOPGczsCcnMGjuIKFffHRH7Ta7HgWTA12MgYAYJw2hshbWHmUHK6jDDheE3BzUZgcZb42uPAz4zlNXPXVt5pPF+TbEZsuqXtvVWQ3wGXPE8pExqvWzFe8xL720GWos5oCp+BMQNh9ghkLfFDHO+2oajfNYwrOPnY510qdnN4Ov9XQ9vhI/+al6ON74WqsPjzVbmsoPmammDJ8J1/22/O8CRHbD67sYpxZxRcPJNZov44c/NeW1L9jV9jTMaxp8Hk75ltmB2ZJUxn9v8jvK/MLsr7FljXv4/WsIoc8GMY682F+noih1vmS3W7nJzzt/Ln4XPnzMXd7BY4eLHYMrlXXvvDuiXLZ8i0vdZrZaGfqQ3nzWGsmova786wrtfFvDulwWUVntZnn2I5dmHcNqsjE+NJrl+DtTYMFJiwhgcHYbXH6DC7aOy1kel20tlrQ+ASUNimTYsnkHRLbSUiHwTWa3mxP2h5K0xA257LXEJI2Hhu+aKY5X5dd0Wihu7LlTkmS1+5YfMbf+6pq+PHQbHnINv1Gze2lbOOeddiLW10JJ2LHzrSXNhgvV/N1f8Ktptvm9NibnwQn2ZrnmtY/1QBx0D334J9n0Iq35pBs41v2vhc44yF10Yf37dQLBOjvK3u8yuGEljzNZcMIPy3g/MEP7lm2YYXf1rePc+GDcfMq+DEae23lXjaIGA2a/5/boFeYadDJc9a/YvHjLdrMfPn4PXfmj+ITL1yo6Vu77/rc3ZbxZ9UPgU+QaIjXBw3pQ0zpuShs8fYMP+ElZvN1eO2ldUzaaDZUBZp983PSGc44bFMy09jpTYcGq8Pqrcfqo95m2t18/Q+HAmDYllfGoMYQ6NWhUJms6Mso8aBCff2PJzhmEG0ZJ9jVtpjnkp/ph5MHgCWCwYXi+BL1te0KCZ+OEw5/81PvZU1S3R+xWU55r9QqObz5LTphGnwMJ3zG4OG54xl9FNm2auopZ2rNmyGmyxQ81+tMdeBe7KxnMf2mAOtNr2f4ClsftC1CDzNjzB7NNZc1RLdVWheQtwwg9gzm/MlnEw/3g5789my+eGZ8y+oIYBx3679bIVbIdNL8OWfzV2M0ieDNO/a7ac9uGpqhQ+Rb5h7DYrJ45M5MSRifx8/nj2FFax50gVeWU15JXXkltWa86JWu7G5bAS5bIT5XIQHWYnOsxOrdfPxgOl7Cqo5EBxDQeKa/i/jYfbPa/NamFscjSTh8QwPjWG2HAHEU47kS5bw21cuJNB0S5s1r7/l7vIgGGx1A1sSmp7Cd3ucEbWLSc7uXvvY7Wag3JCMDCnGVeUecn9uAVml4QNz5qtybVl5vyw1YXQ3sJp9nA49wGYdnXz56xWOPdPZgD97Cl4/UdmEI1Orgu2dVtNiXnevKNmE3LFmDMx5G+BN5dA1q/MADr9e93/znuAwqfIN5jFYmHUoChGDer8HIDltV421c2Tmp1TQlmNl0iXnUinnQiXjQinDYfNyp4jVXxxqIyiKg/bc8vZntv2JMR2q4XUuDDSYsMZEhdOcoyTA4csHPhgLzabDavF/L/SbrUyKNpFal1XgcHRYTjtGkQlIiGQMhnOvR/m/d5s2azMN7eqI3VdG4rNlseIhMbZCcITIC697dHzViuc+6A5a8D6J+DAJ20c6zC7F0y9AsbMNaeQ2viSGVyLdpm3nz0FI88wuzj0ocvxCp8i0iUxYQ5mjRnErDHtd7o3DIPcslo2Hyzji0Nl7D5SSaXbR7XHT9VRt6U1XnwBo6FFtZGN/+bsavMcFgskRrpIinIS7jTDb7jDRpjDvI0OcxAf4SAu0klcuIP4CCdxEQ6iXHYiXXaiXHbCHNYWV2vrSYZhUFbjJSbM0bDwQLAcqXCz8UApk4fEkhIbnFVuROQoVlvdpfZBQBuDvjrDYjGD7XELzK4Klflmv9zKAnN0vhGAceeac8se3WfWEWbOs3rSj8z+sZ89Zc6bm5DRp4InKHyKSAhYLBbS4sJJiwvnnEmtL1DpDxjkl9dyuLSGQ6U1HC6t5WBxFV/t3c/Q9KFYLFYChgEGePwBCirc5JXVkldWi8cfoLDSTWGlu9X3b4/VApEuOzFhDhKjnCRGmqtc1d932W34Agb+QMC89Rv4DYPYcAdJUS6SolwMinaSGOkiOsxOtdcM1VVuH5Vu835eWS17C6vYW1TF3iNV7C+qosrjZ1hCBFeekM63MocyOLrrQdEwDNbvK+Efn+zn7S9y8frNaQ6OTY/jnEkpzJ2YQkZSZJPXVLp97C+qIqeoGr9hEOk0A3mE00aUy2zJjnY5eiWci3xjpU5pe67U1lgskDHL3CoLzBkU+hiFTxHpM2zWxpBa3/PMnBZkL/PnT2p1WhDDMCiu8pBbVktxlYdar58arzngqdpjbhW1PkqrPZRUeyip9lJa7aG02muGQ485JUzAgIpaHxW1Pg6Vtj2Jf7DlFFfzh7d38OCqnZw9PplvnziMWaOTOtwaWun28Vr2IZ7/eD878isa9qcnhHOwpIaNB0rZeKCU3731JWOTo5iQGsPBkhr2FVV3OLDbrRai6vr+RrscpMWFs3BWBieNTOzSZxaRHtaNRQV6ksKniPR7FoulroWya1M/BQJGk1bKshovxVUeiio9FFa5zdtKNz6/gc1qwW61mLc2C2ChrMZDYYV5bGGFm/LaxpYGu9XScFk/0mUjKcrFiKRIMhIjzdukCAZFhbFqWx4vfZrD5zmlvL01j7e35jE42kVKbFhDS2SUy0aky07AgOIqt1nGKg/FVWaQrhfusHHRtDSuPnE4k4bEUlBey6pt+azcmsfHu4vYmV/JzvzKJt9BQqSTYQkRuOzWhm4QVR4f1W4/lR4fhgG+gEFptbfuXDVsyy1n9fZ8Zo1J4idzjuHY9Lguff8i8s2i8Cki33hWq6VuVH9w/kl0+/xUuf1EOG247B27VH3Z9HQum57Ol3nlvPzpAZZ/fpCCCjcFFR3vRjByUCTXnDScS44bSmx4Yyvx4JgwvnPScL5z0nDKqr2882U+uWW1DEuIYERiJMMSI5oc/3WGYVDl8VNZ66Oi1kt53e3q7fm8/OkB1u4qZO2uQs4en8xP5oxlfGrPLwYiIv2XwqeISJC57DZc9q7NaTouJYa7L5jI7eeMY/PBUipqzRbIqro+o5VuX93gKicJkS4SIp0kRjnN20hnu0E3NsLBJccN7VSZLJbGcH70wKXTjxnMD08dxZ/f2cXyzw+yens+q7fnc8KIBEYNjiIjKYKMpCgykiJJjR6AqxqJSJcofIqI9EHhThsn9oO+lOkJEdx/2VQWnTaKP63eyZubc/l0XzGf7itucpzFAg6Ljbs3vUdY3SwELru1oWXYagGrxYLVYgELuOxWYsIdxIQ5iAmzExNuzjUb7rARftRMBmEOG5EuG2lx4cSEKeBK9/gDBgUVtaTEhGlwXQ9S+BQRkW4bPTiKv111HEtmV7LpQCn7CqvYU1jFvrpR/VUePx7DgqfaC3jbfb+uiAmzMzQ+gqHx4QyNjyDCaaOkbmBZcZU52KysxktSlIuJaTFMSIthQmoM41JjgtblQvqfIxVu1uw8wvs7Cli7q5CyGi+JkU5OHpXIzNFJzByVRHpCuMJoEOm3TUREgqalRQsMwyC/tIo3V73DyTNPxY+VWp85G4HHFyBgmMfU3/oNA7c3QHmtl4paH+U13ob71R7zdeYWoMbrp6LWS0m12Rd1W24529pZyCC3rJYth5ouJzskLhyrFTy+AF6/gccXwOMP4A+Yg8xsFnOgmbVuwFmYw9aw6leUy05UmDlnbH1rrtNuxWkzbyOc5kCzpOj66bhcRDptVHn8fJlbztbD5Ww9XMbWw+XsOVLF2OQozh6fzNkTkhmXEq3QE2SVbh8b9pfw6d4i1uw8wheHmv+8FFV5+O/mXP67ORcwfz7OHj+YG88c3a2p0MSk8CkiIj2qfjaCpDAYkxzV6pRZ3VHt8XGopIaDJTUcLKnmQEkNtV4/cRFO4iMcJEQ6iYtwEhvu4HBpDdsOmyF12+Fy8spr25xayx8wgl7eMIcVty+A0cJbbzpYxqaDZTyQtbMh9MwcnURUmB2HzYrdasFhs2KzWnDYLNitVuy2o/ZZzZW+/IZBoH4LNJ63vstDMEKtxxcgO6eE0hovJ2YkEBfh7PZ7BltptYdP9hTx6d4S1u8rZuvhMr5epZOHxHL6MYM4/ZhBTEyLZfPBMtZ9VchHuwvJzinlUGkNz368n39tOMgNZ4zm+lMyCHN0rV+3KHyKiMgAEOG0MyY5mjHJ0e0ee2x6HPMnpzY8Lqp0s6+oCqvFDHAuuxVHXaulzWrBHzAaNl/dbX2La2XdvLAVbh+VtT7cPn9Dq6nHZ26Vbh9FVR6OVJiLIJitt2YaTIkJY0JaDBPrtoykKLJzSli9PZ8PvypsCD3Pfrw/qN+XxWJOyRXusBET7iCtfknbeHOe3SFx4SRFuYgNdxAbbi4wAGAYsLewio/3lrJ21xE+3l3UME+u1QJT0+M4bewgThs7iClD47BZLU3m4TXn4nUzNjmayUNisdt6Zklcf8Bg7a4jvPrZQbK25ePxB5o8n54QzvEjEpg5KolTxw5iUHTTadpOyEjghIwEbp09liq3j//tLeIv73zFxgOl/HHlDl76NIefzx/PvEkpapnuAoVPERH5RuvOHLFdUeX2UVjpJtJlJ6mF8x6TEs2VJwyjxuNn3VeFrN6ez+aDZXj8AXx+s1uAL2B2CfD6DXPfUQH56yx1g7mgsRXXMGhYgKGoysPewqo2y+y0W4kNs+N22yj/ZF2T58yZF5zsKqgkO6eU7JxSHlq9i7gIc8BYXnktHl+g2XtGOm0cn5HASSMTOXlkIqMGR7GvsIrdRyrZXVDJV0cq2V1QRZjTRuaweDKHxzN9RDzJMa1f9t5XWMW/NhzkXxsOklde27B/zOAoThyZwAkZiRw/Ip7U2PA2P2+TcrrsnDkumdPHDub/Nh3i92/t4GBJDTe88DknZCTwg1kjOW54PAmRfa/Vt69S+BQREQmhSJe5aEB7wp02zp5g9v3sqEBd66ylYfYAmrTMef2BxhXAPAFqfX6KKj3kltVwqKSGw2U1HCqt5VBJNSXVXspqvPgDZh/YI5UewLzUf/yIBGaNGcSsMUlMSI3BarWQW1bDBzuPsGbnEdbuKjxqQQLToGgXqbFhxIQ52HKojLIaL+/vOML7O460+7k2HSjlqXV7AbP/5bRhcVgtloYBZSXVHsqqvVS4Gxd4iItwcNGxQ7hs+lAmpsV2+DtsjdVq4eJpQ5k7MYVH1+zhsTW7+XRvMZ/uNWd2GJEYwXHD4pk2LI5j0+PJGBSpgWyt0LciIiIyQFitFpxtLMnqsJldCqKPnpaqjWxbv8BAabWHoooa3vvgQ7578RxiI5u3HKbGhnPF8cO44vhh+PwBNh8qwx8wSIkJIzkmDKe98RJ7IGCwPa+cT/YU88meIv63p4jyWh8JkU5GDYpk9OCohsFr5bVeNuwv4bN9JXyZV86h0ppW++haLHDqmEFcPj2dsycM7vJ8u22JcNpZMnssVxyfzrL3vuLjPUXsOVLFvqJq9hVVszz7UMOxcREOc/aFOHMWhsQoV10fXPOPhIDReBsIGPgDNPTT9QUMqt0+Kt1+Kt1eqtx+c55fYFxqNJOGxDK5bmupr63HF6Ci1osBLbaw9yaFTxEREWnR0QsMJEc52Bdthq/22G1WjhsW3+rzVquFiWmxTEyL5fpTMvAHDCrdvlZX2rrw2CGAOVJ9Y04pWw6V4bBZGgaU1d8mRbtCNt/rkLhwfnPxZMAc1LTxgNnl4POcEr44VEZJXctvabW3xRH13bGnsIoVW/IaHg+NDycx0mnODlG3Apm7rqvDnAnJPL5gelDP310KnyIiItKrbFZLm0u81oty2TllTBKnjEkKQak6Li7CyenHDOb0YwY37Kuo9XKotIaDxeYMDAdLaiiu9mC3Wszpu+qm8Kqfvstad99qAZvFgsViIdJlI8rlICrMTlTdfbfPz9bD5Ww5VMYXh8rYX1RdN8tDy63BXx9s1RcofIqIiIgEWXSYg3EpDsalxAT9vWeNGdRwv6zGy9bDZVS7/XVzzzqazEHbUzMKdIfCp4iIiEg/FRvuYMaovtUS3J6+F4dFREREZMBS+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkFH4FBEREZGQUfgUERERkZBR+BQRERGRkOlS+Fy2bBkZGRmEhYWRmZnJ2rVrWz12+fLlzJ49m0GDBhETE8PJJ5/MypUru1xgEREREem/Oh0+X3nlFRYvXsxdd91FdnY2s2bNYt68eeTk5LR4/AcffMDs2bNZsWIFGzZs4IwzzuD8888nOzu724UXERERkf6l0+HzwQcf5Prrr2fhwoWMHz+ehx56iPT0dB555JEWj3/ooYf42c9+xvHHH8+YMWP47W9/y5gxY/jPf/7T7cKLiIiISP9i78zBHo+HDRs2cMcddzTZP2fOHD766KMOvUcgEKCiooKEhIRWj3G73bjd7obH5eXlAHi9Xrxeb2eK3CX15wjFuaTnqB4HBtXjwKB67P9UhwNDT9ZjR9+zU+GzsLAQv99PcnJyk/3Jycnk5eV16D0eeOABqqqquPzyy1s9ZunSpdxzzz3N9q9atYqIiIjOFLlbsrKyQnYu6Tmqx4FB9TgwqB77P9XhwNAT9VhdXd2h4zoVPutZLJYmjw3DaLavJS+99BJ33303//d//8fgwYNbPe7OO+9kyZIlDY/Ly8tJT09nzpw5xMTEdKXIneL1esnKymL27Nk4HI4eP5/0DNXjwKB6HBhUj/2f6nBg6Ml6rL9S3Z5Ohc+kpCRsNluzVs6CgoJmraFf98orr3D99dfz6quvcvbZZ7d5rMvlwuVyNdvvcDhC+gMf6vNJz1A9Dgyqx4FB9dj/qQ4Hhp6ox46+X6cGHDmdTjIzM5s11WZlZTFjxoxWX/fSSy9x3XXX8eKLL3Luued25pQiIiIiMoB0+rL7kiVLuOaaa5g+fTonn3wyjz/+ODk5OSxatAgwL5kfOnSI5557DjCD54IFC/jzn//MSSed1NBqGh4eTmxsbBA/ioiIiIj0dZ0On1dccQVFRUXce++95ObmMmnSJFasWMHw4cMByM3NbTLn52OPPYbP5+PGG2/kxhtvbNh/7bXX8swzz3T/E4iIiIhIv9GlAUc33HADN9xwQ4vPfT1Qvv/++105hYiIiIgMQFrbXURERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQkbhU0RERERCRuFTREREREJG4VNEREREQqZL4XPZsmVkZGQQFhZGZmYma9eubfP4NWvWkJmZSVhYGCNHjuTRRx/tUmFFREREpH/rdPh85ZVXWLx4MXfddRfZ2dnMmjWLefPmkZOT0+Lxe/fuZf78+cyaNYvs7Gx+/vOfc8stt/Dvf/+724UXERERkf6l0+HzwQcf5Prrr2fhwoWMHz+ehx56iPT0dB555JEWj3/00UcZNmwYDz30EOPHj2fhwoV873vf4/777+924UVERESkf7F35mCPx8OGDRu44447muyfM2cOH330UYuv+fjjj5kzZ06TfXPnzuXJJ5/E6/XicDiavcbtduN2uxsel5WVAVBcXIzX6+1MkbvE6/VSXV1NUVFRi+WT/kH1ODCoHgcG1WP/pzocGHqyHisqKgAwDKPN4zoVPgsLC/H7/SQnJzfZn5ycTF5eXouvycvLa/F4n89HYWEhqampzV6zdOlS7rnnnmb7MzIyOlNcEREREQmxiooKYmNjW32+U+GznsViafLYMIxm+9o7vqX99e68806WLFnS8DgQCFBcXExiYmKb5wmW8vJy0tPTOXDgADExMT1+PukZqseBQfU4MKge+z/V4cDQk/VoGAYVFRWkpaW1eVynwmdSUhI2m61ZK2dBQUGz1s16KSkpLR5vt9tJTExs8TUulwuXy9VkX1xcXGeKGhQxMTH6BRsAVI8Dg+pxYFA99n+qw4Ghp+qxrRbPep0acOR0OsnMzCQrK6vJ/qysLGbMmNHia04++eRmx69atYrp06erz4iIiIjIN0ynR7svWbKEv//97zz11FNs376dW2+9lZycHBYtWgSYl8wXLFjQcPyiRYvYv38/S5YsYfv27Tz11FM8+eST/PSnPw3epxARERGRfqHTfT6vuOIKioqKuPfee8nNzWXSpEmsWLGC4cOHA5Cbm9tkzs+MjAxWrFjBrbfeyt/+9jfS0tL4y1/+wqWXXhq8TxFkLpeLX//6180u/Uv/onocGFSPA4Pqsf9THQ4MfaEeLUZ74+FFRERERIJEa7uLiIiISMgofIqIiIhIyCh8ioiIiEjIKHyKiIiISMgofH7NsmXLyMjIICwsjMzMTNauXdvbRZI2LF26lOOPP57o6GgGDx7MRRddxI4dO5ocYxgGd999N2lpaYSHh3P66aezdevWXiqxdMTSpUuxWCwsXry4YZ/qsX84dOgQ3/nOd0hMTCQiIoJjjz2WDRs2NDyveuz7fD4fv/jFL8jIyCA8PJyRI0dy7733EggEGo5RPfY9H3zwAeeffz5paWlYLBZef/31Js93pM7cbjc333wzSUlJREZGcsEFF3Dw4MGgl1Xh8yivvPIKixcv5q677iI7O5tZs2Yxb968JlNHSd+yZs0abrzxRj755BOysrLw+XzMmTOHqqqqhmP+8Ic/8OCDD/Lwww+zfv16UlJSmD17NhUVFb1YcmnN+vXrefzxx5kyZUqT/arHvq+kpISZM2ficDh466232LZtGw888ECTFepUj33f73//ex599FEefvhhtm/fzh/+8Af++Mc/8te//rXhGNVj31NVVcXUqVN5+OGHW3y+I3W2ePFiXnvtNV5++WU+/PBDKisrOe+88/D7/cEtrCENTjjhBGPRokVN9o0bN8644447eqlE0lkFBQUGYKxZs8YwDMMIBAJGSkqK8bvf/a7hmNraWiM2NtZ49NFHe6uY0oqKigpjzJgxRlZWlnHaaacZP/7xjw3DUD32F7fffrtxyimntPq86rF/OPfcc43vfe97TfZdcsklxne+8x3DMFSP/QFgvPbaaw2PO1JnpaWlhsPhMF5++eWGYw4dOmRYrVbj7bffDmr51PJZx+PxsGHDBubMmdNk/5w5c/joo496qVTSWWVlZQAkJCQAsHfvXvLy8prUq8vl4rTTTlO99kE33ngj5557LmeffXaT/arH/uGNN95g+vTpXHbZZQwePJhp06bxxBNPNDyveuwfTjnlFN555x127twJwKZNm/jwww+ZP38+oHrsjzpSZxs2bMDr9TY5Ji0tjUmTJgW9Xju9wtFAVVhYiN/vJzk5ucn+5ORk8vLyeqlU0hmGYbBkyRJOOeUUJk2aBNBQdy3V6/79+0NeRmndyy+/zOeff8769eubPad67B/27NnDI488wpIlS/j5z3/Op59+yi233ILL5WLBggWqx37i9ttvp6ysjHHjxmGz2fD7/fzmN7/h29/+NqDfx/6oI3WWl5eH0+kkPj6+2THBzkEKn19jsViaPDYMo9k+6ZtuuukmNm/ezIcfftjsOdVr33bgwAF+/OMfs2rVKsLCwlo9TvXYtwUCAaZPn85vf/tbAKZNm8bWrVt55JFHWLBgQcNxqse+7ZVXXuH555/nxRdfZOLEiWzcuJHFixeTlpbGtdde23Cc6rH/6Uqd9US96rJ7naSkJGw2W7N0X1BQ0OwvBel7br75Zt544w3ee+89hg4d2rA/JSUFQPXax23YsIGCggIyMzOx2+3Y7XbWrFnDX/7yF+x2e0NdqR77ttTUVCZMmNBk3/jx4xsGber3sX+47bbbuOOOO7jyyiuZPHky11xzDbfeeitLly4FVI/9UUfqLCUlBY/HQ0lJSavHBIvCZx2n00lmZiZZWVlN9mdlZTFjxoxeKpW0xzAMbrrpJpYvX867775LRkZGk+czMjJISUlpUq8ej4c1a9aoXvuQs846iy1btrBx48aGbfr06Vx99dVs3LiRkSNHqh77gZkzZzab6mznzp0MHz4c0O9jf1FdXY3V2jQe2Gy2hqmWVI/9T0fqLDMzE4fD0eSY3Nxcvvjii+DXa1CHL/VzL7/8suFwOIwnn3zS2LZtm7F48WIjMjLS2LdvX28XTVrxox/9yIiNjTXef/99Izc3t2Grrq5uOOZ3v/udERsbayxfvtzYsmWL8e1vf9tITU01ysvLe7Hk0p6jR7sbhuqxP/j0008Nu91u/OY3vzF27dplvPDCC0ZERITx/PPPNxyjeuz7rr32WmPIkCHGf//7X2Pv3r3G8uXLjaSkJONnP/tZwzGqx76noqLCyM7ONrKzsw3AePDBB43s7Gxj//79hmF0rM4WLVpkDB061Fi9erXx+eefG2eeeaYxdepUw+fzBbWsCp9f87e//c0YPny44XQ6jeOOO65hyh7pm4AWt6effrrhmEAgYPz61782UlJSDJfLZZx66qnGli1beq/Q0iFfD5+qx/7hP//5jzFp0iTD5XIZ48aNMx5//PEmz6se+77y8nLjxz/+sTFs2DAjLCzMGDlypHHXXXcZbre74RjVY9/z3nvvtfj/4bXXXmsYRsfqrKamxrjpppuMhIQEIzw83DjvvPOMnJycoJfVYhiGEdy2VBERERGRlqnPp4iIiIiEjMKniIiIiISMwqeIiIiIhIzCp4iIiIiEjMKniIiIiISMwqeIiIiIhIzCp4iIiIiEjMKniIiIiISMwqeIiIiIhIzCp4iIiIiEjMKniIiIiISMwqeIiIiIhMz/B+oMICHI4WipAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history_).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f4c38",
   "metadata": {},
   "source": [
    "## Fine-Tuning Hyperparameters\n",
    "\n",
    "We don't know if the default parameters are actually the best, and since we are using a Keras Regressor, we can use some of the *Cross Validation* methods available in Keras.\n",
    "\n",
    "First, we need to define a set of values for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b29c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import loguniform, reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"model__n_hidden\": [0, 1, 2, 3],\n",
    "    \"model__n_neurons\": np.arange(1, 100).tolist(),\n",
    "    \"model__learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3498fa9",
   "metadata": {},
   "source": [
    "Then, we train the model using a randomized cross validation, sampling ten different configurations with `k=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c00ee89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.9124 - val_loss: 0.6507\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.5579 - val_loss: 0.5208\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4814 - val_loss: 0.4699\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4483 - val_loss: 0.4473\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4306 - val_loss: 0.4416\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4172 - val_loss: 0.4229\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4098 - val_loss: 0.4243\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4014 - val_loss: 0.4449\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3985 - val_loss: 0.4134\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3890 - val_loss: 0.4385\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3861 - val_loss: 0.4048\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3792 - val_loss: 0.3981\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3785 - val_loss: 0.4259\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3717 - val_loss: 0.3977\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3702 - val_loss: 0.4058\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3696 - val_loss: 0.3877\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3626 - val_loss: 0.3984\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3614 - val_loss: 0.3857\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3565 - val_loss: 0.3919\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3571 - val_loss: 0.3777\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3545 - val_loss: 0.3909\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3487 - val_loss: 0.3888\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3483 - val_loss: 0.4014\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3450 - val_loss: 0.3858\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3473 - val_loss: 0.3711\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3434 - val_loss: 0.3701\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3425 - val_loss: 0.3897\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3410 - val_loss: 0.3707\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3411 - val_loss: 0.3624\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3338 - val_loss: 0.3762\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3371 - val_loss: 0.3649\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3356 - val_loss: 0.3637\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3325 - val_loss: 0.3618\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3292 - val_loss: 0.3591\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3272 - val_loss: 0.3644\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3275 - val_loss: 0.3739\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3247 - val_loss: 0.3741\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3263 - val_loss: 0.3572\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3227 - val_loss: 0.3518\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3216 - val_loss: 0.3591\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3206 - val_loss: 0.3492\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3209 - val_loss: 0.3465\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3178 - val_loss: 0.3492\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3168 - val_loss: 0.3514\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3177 - val_loss: 0.3507\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3182 - val_loss: 0.3484\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3155 - val_loss: 0.3408\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3137 - val_loss: 0.3459\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3214 - val_loss: 0.3649\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3191 - val_loss: 0.3501\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3134 - val_loss: 0.3790\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3096 - val_loss: 0.3448\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3060 - val_loss: 0.3581\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3072 - val_loss: 0.3464\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3057 - val_loss: 0.3447\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3044 - val_loss: 0.3436\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3038 - val_loss: 0.3482\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.3029 - val_loss: 0.3371\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3013 - val_loss: 0.3410\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3025 - val_loss: 0.3358\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2982 - val_loss: 0.3506\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2985 - val_loss: 0.3340\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2970 - val_loss: 0.3424\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2970 - val_loss: 0.3532\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3011 - val_loss: 0.3303\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2969 - val_loss: 0.3389\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2950 - val_loss: 0.3438\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.2945 - val_loss: 0.3412\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2947 - val_loss: 0.3353\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2920 - val_loss: 0.3279\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2913 - val_loss: 0.3353\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2905 - val_loss: 0.3366\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2895 - val_loss: 0.3488\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2889 - val_loss: 0.3257\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2886 - val_loss: 0.3312\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2880 - val_loss: 0.3430\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2865 - val_loss: 0.3378\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2864 - val_loss: 0.3420\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2860 - val_loss: 0.3485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2883 - val_loss: 0.3269\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.2875 - val_loss: 0.3292\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2849 - val_loss: 0.3275\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2841 - val_loss: 0.3272\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2832 - val_loss: 0.3594\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2838 - val_loss: 0.3206\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2825 - val_loss: 0.3290\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2815 - val_loss: 0.3297\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2842 - val_loss: 0.3237\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2812 - val_loss: 0.3274\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2808 - val_loss: 0.3226\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2796 - val_loss: 0.3386\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.2820 - val_loss: 0.3246\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2791 - val_loss: 0.3592\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2820 - val_loss: 0.3190\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.2782 - val_loss: 0.3351\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2808 - val_loss: 0.3201\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.2791 - val_loss: 0.3292\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2806 - val_loss: 0.3161\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2778 - val_loss: 0.3251\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2777 - val_loss: 0.3314\n",
      "121/121 [==============================] - 0s 273us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 1.0479 - val_loss: 0.6630\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.5672 - val_loss: 0.6011\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6670 - val_loss: 0.5375\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.4809 - val_loss: 0.4913\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.4365 - val_loss: 0.4584\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4230 - val_loss: 0.4497\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4148 - val_loss: 0.4471\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4066 - val_loss: 0.4376\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.4015 - val_loss: 0.4325\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3958 - val_loss: 0.4262\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3909 - val_loss: 0.4199\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3870 - val_loss: 0.4185\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3819 - val_loss: 0.4198\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3784 - val_loss: 0.4177\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3758 - val_loss: 0.4206\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3718 - val_loss: 0.4122\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3688 - val_loss: 0.4087\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3644 - val_loss: 0.4037\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3622 - val_loss: 0.4061\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3599 - val_loss: 0.4095\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3584 - val_loss: 0.3963\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3543 - val_loss: 0.3984\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3538 - val_loss: 0.4069\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3501 - val_loss: 0.4002\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3493 - val_loss: 0.3946\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3440 - val_loss: 0.4082\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.3460 - val_loss: 0.3948\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3422 - val_loss: 0.3940\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3417 - val_loss: 0.3919\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3382 - val_loss: 0.3916\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3371 - val_loss: 0.3939\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3371 - val_loss: 0.3832\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3350 - val_loss: 0.3879\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3340 - val_loss: 0.3826\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3303 - val_loss: 0.3830\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3314 - val_loss: 0.3824\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3272 - val_loss: 0.3900\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3289 - val_loss: 0.3804\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3256 - val_loss: 0.3820\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3249 - val_loss: 0.3796\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3210 - val_loss: 0.3768\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3224 - val_loss: 0.3829\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3208 - val_loss: 0.3811\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3213 - val_loss: 0.3743\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3194 - val_loss: 0.3718\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3194 - val_loss: 0.3733\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3170 - val_loss: 0.3723\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3155 - val_loss: 0.3773\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3145 - val_loss: 0.3693\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3141 - val_loss: 0.3749\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3142 - val_loss: 0.3714\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3113 - val_loss: 0.3689\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3099 - val_loss: 0.3722\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3111 - val_loss: 0.3822\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3074 - val_loss: 0.3620\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3058 - val_loss: 0.3611\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3074 - val_loss: 0.3729\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 496us/step - loss: 0.3068 - val_loss: 0.3639\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3060 - val_loss: 0.3680\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3039 - val_loss: 0.3598\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3025 - val_loss: 0.3604\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3017 - val_loss: 0.3644\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.3022 - val_loss: 0.3613\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2993 - val_loss: 0.3689\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.3019 - val_loss: 0.3628\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2993 - val_loss: 0.3638\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2993 - val_loss: 0.3556\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2998 - val_loss: 0.3660\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2982 - val_loss: 0.3630\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.2978 - val_loss: 0.3506\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2957 - val_loss: 0.3498\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2948 - val_loss: 0.3558\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2943 - val_loss: 0.3574\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2949 - val_loss: 0.3618\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2935 - val_loss: 0.3537\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2948 - val_loss: 0.3548\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2921 - val_loss: 0.3575\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2922 - val_loss: 0.3640\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2922 - val_loss: 0.3465\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2923 - val_loss: 0.3559\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2909 - val_loss: 0.3476\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2882 - val_loss: 0.3460\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.2875 - val_loss: 0.3412\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2878 - val_loss: 0.3521\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.2887 - val_loss: 0.3467\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.2869 - val_loss: 0.3607\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.2873 - val_loss: 0.3555\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.2867 - val_loss: 0.3454\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2858 - val_loss: 0.3544\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.2857 - val_loss: 0.3387\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.2848 - val_loss: 0.3443\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.2862 - val_loss: 0.3501\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2828 - val_loss: 0.3530\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2857 - val_loss: 0.3414\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.2845 - val_loss: 0.3401\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2838 - val_loss: 0.3450\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.2834 - val_loss: 0.3388\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2822 - val_loss: 0.3461\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2812 - val_loss: 0.3471\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2826 - val_loss: 0.3484\n",
      "121/121 [==============================] - 0s 274us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 653us/step - loss: 1.0299 - val_loss: 0.7636\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.9394 - val_loss: 0.7478\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.5450 - val_loss: 0.4927\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4633 - val_loss: 0.4695\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4433 - val_loss: 0.4532\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.4292 - val_loss: 0.4391\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4179 - val_loss: 0.4336\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4250\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4021 - val_loss: 0.4216\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3959 - val_loss: 0.4233\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3924 - val_loss: 0.4153\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3891 - val_loss: 0.4127\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3828 - val_loss: 0.4089\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3796 - val_loss: 0.4083\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3763 - val_loss: 0.4192\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3726 - val_loss: 0.4019\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3699 - val_loss: 0.4071\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3647 - val_loss: 0.4028\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3648 - val_loss: 0.3921\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3618 - val_loss: 0.3971\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3581 - val_loss: 0.4052\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3565 - val_loss: 0.3887\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3539 - val_loss: 0.3895\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3515 - val_loss: 0.4009\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3476 - val_loss: 0.3896\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.3466 - val_loss: 0.3829\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3433 - val_loss: 0.3907\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3423 - val_loss: 0.3805\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3396 - val_loss: 0.3782\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3379 - val_loss: 0.3752\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3377 - val_loss: 0.3732\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3365 - val_loss: 0.3794\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3349 - val_loss: 0.3715\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3303 - val_loss: 0.3780\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3296 - val_loss: 0.3896\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 472us/step - loss: 0.3301 - val_loss: 0.3684\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3266 - val_loss: 0.4243\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3260 - val_loss: 0.3628\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3239 - val_loss: 0.3755\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3243 - val_loss: 0.3636\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3199 - val_loss: 0.3633\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3226 - val_loss: 0.3870\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3212 - val_loss: 0.3786\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3183 - val_loss: 0.3634\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3183 - val_loss: 0.3549\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3180 - val_loss: 0.3569\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3155 - val_loss: 0.3680\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3154 - val_loss: 0.3701\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3138 - val_loss: 0.3520\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3137 - val_loss: 0.3496\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3109 - val_loss: 0.3551\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3122 - val_loss: 0.3603\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3099 - val_loss: 0.3536\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.3085 - val_loss: 0.3618\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3092 - val_loss: 0.3546\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3086 - val_loss: 0.3564\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3067 - val_loss: 0.3556\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3081 - val_loss: 0.3453\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3070 - val_loss: 0.3527\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3057 - val_loss: 0.3567\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3059 - val_loss: 0.3454\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3032 - val_loss: 0.3509\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3053 - val_loss: 0.3529\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3038 - val_loss: 0.3470\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3016 - val_loss: 0.3630\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3033 - val_loss: 0.3469\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3008 - val_loss: 0.3426\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3012 - val_loss: 0.3532\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2998 - val_loss: 0.3465\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2989 - val_loss: 0.3456\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2998 - val_loss: 0.3403\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2981 - val_loss: 0.3693\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3015 - val_loss: 0.3425\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2976 - val_loss: 0.3390\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.2999 - val_loss: 0.3404\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2990 - val_loss: 0.3373\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.2975 - val_loss: 0.3397\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2984 - val_loss: 0.3453\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2986 - val_loss: 0.3338\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2962 - val_loss: 0.3521\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2994 - val_loss: 0.3351\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2950 - val_loss: 0.3891\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2938 - val_loss: 0.3382\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2960 - val_loss: 0.3568\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2965 - val_loss: 0.3364\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2943 - val_loss: 0.3420\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.2935 - val_loss: 0.3430\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2929 - val_loss: 0.3343\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2920 - val_loss: 0.3423\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2936 - val_loss: 0.3418\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2920 - val_loss: 0.3359\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2922 - val_loss: 0.3529\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2923 - val_loss: 0.3366\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2915 - val_loss: 0.3326\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.2901 - val_loss: 0.3298\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.2903 - val_loss: 0.3365\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.2884 - val_loss: 0.3358\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2901 - val_loss: 0.3346\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.2890 - val_loss: 0.3313\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2907 - val_loss: 0.3323\n",
      "121/121 [==============================] - 0s 272us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 5.0176 - val_loss: 4.4805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 4.0143 - val_loss: 3.6299\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 3.2834 - val_loss: 3.0104\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 2.7512 - val_loss: 2.5595\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 2.3637 - val_loss: 2.2312\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 2.0814 - val_loss: 1.9923\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 1.8760 - val_loss: 1.8184\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 1.7262 - val_loss: 1.6917\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.6171 - val_loss: 1.5996\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 1.5377 - val_loss: 1.5325\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 1.4798 - val_loss: 1.4836\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 1.4376 - val_loss: 1.4481\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.4069 - val_loss: 1.4223\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 486us/step - loss: 1.3845 - val_loss: 1.4035\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 1.3683 - val_loss: 1.3899\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3564 - val_loss: 1.3800\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 1.3478 - val_loss: 1.3728\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3416 - val_loss: 1.3676\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3370 - val_loss: 1.3638\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3337 - val_loss: 1.3610\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3313 - val_loss: 1.3591\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3295 - val_loss: 1.3576\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3282 - val_loss: 1.3566\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 1.3273 - val_loss: 1.3558\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3266 - val_loss: 1.3553\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3261 - val_loss: 1.3549\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3257 - val_loss: 1.3546\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3254 - val_loss: 1.3544\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 1.3253 - val_loss: 1.3542\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3251 - val_loss: 1.3541\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3250 - val_loss: 1.3541\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3249 - val_loss: 1.3540\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3249 - val_loss: 1.3540\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3248 - val_loss: 1.3539\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3248 - val_loss: 1.3539\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3248 - val_loss: 1.3539\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 1.3248 - val_loss: 1.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 611us/step - loss: 1.3247 - val_loss: 1.3539\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 1.3247 - val_loss: 1.3538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3247 - val_loss: 1.3538\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 1.3246 - val_loss: 1.3538\n",
      "121/121 [==============================] - 0s 284us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 679us/step - loss: 2.5144 - val_loss: 2.0628\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 1.6990 - val_loss: 1.4674\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.2526 - val_loss: 1.1415\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 1.0098 - val_loss: 0.9600\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.8710 - val_loss: 0.8506\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.7847 - val_loss: 0.7792\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.7268 - val_loss: 0.7306\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.6862 - val_loss: 0.6952\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6557 - val_loss: 0.6682\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6320 - val_loss: 0.6467\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6127 - val_loss: 0.6295\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.5971 - val_loss: 0.6155\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5844 - val_loss: 0.6039\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5736 - val_loss: 0.5941\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5644 - val_loss: 0.5860\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5566 - val_loss: 0.5792\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5500 - val_loss: 0.5734\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5442 - val_loss: 0.5683\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5393 - val_loss: 0.5639\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5349 - val_loss: 0.5599\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5311 - val_loss: 0.5563\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5275 - val_loss: 0.5529\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5244 - val_loss: 0.5499\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5213 - val_loss: 0.5470\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5186 - val_loss: 0.5444\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5161 - val_loss: 0.5420\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5137 - val_loss: 0.5396\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5115 - val_loss: 0.5373\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5093 - val_loss: 0.5353\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5074 - val_loss: 0.5332\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.5055 - val_loss: 0.5313\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5037 - val_loss: 0.5293\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5019 - val_loss: 0.5274\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5003 - val_loss: 0.5256\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4986 - val_loss: 0.5239\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4971 - val_loss: 0.5223\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4956 - val_loss: 0.5207\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4941 - val_loss: 0.5191\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4928 - val_loss: 0.5176\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4915 - val_loss: 0.5163\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4901 - val_loss: 0.5151\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4889 - val_loss: 0.5138\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4878 - val_loss: 0.5126\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4867 - val_loss: 0.5115\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4856 - val_loss: 0.5103\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4845 - val_loss: 0.5092\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4835 - val_loss: 0.5083\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4825 - val_loss: 0.5072\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4815 - val_loss: 0.5062\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4806 - val_loss: 0.5053\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4797 - val_loss: 0.5045\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4790 - val_loss: 0.5037\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4781 - val_loss: 0.5029\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4774 - val_loss: 0.5022\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4767 - val_loss: 0.5016\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4759 - val_loss: 0.5009\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4753 - val_loss: 0.5003\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4746 - val_loss: 0.4996\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4740 - val_loss: 0.4990\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4733 - val_loss: 0.4983\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4726 - val_loss: 0.4977\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4720 - val_loss: 0.4973\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4714 - val_loss: 0.4965\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4709 - val_loss: 0.4960\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4704 - val_loss: 0.4955\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4698 - val_loss: 0.4950\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4693 - val_loss: 0.4945\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4688 - val_loss: 0.4939\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4682 - val_loss: 0.4935\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4677 - val_loss: 0.4931\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 484us/step - loss: 0.4673 - val_loss: 0.4926\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4668 - val_loss: 0.4922\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4663 - val_loss: 0.4918\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4659 - val_loss: 0.4914\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4655 - val_loss: 0.4910\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.4650 - val_loss: 0.4907\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4646 - val_loss: 0.4903\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4642 - val_loss: 0.4900\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4638 - val_loss: 0.4897\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4634 - val_loss: 0.4893\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4630 - val_loss: 0.4890\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4626 - val_loss: 0.4887\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4621 - val_loss: 0.4885\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4618 - val_loss: 0.4882\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4614 - val_loss: 0.4878\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4610 - val_loss: 0.4876\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4606 - val_loss: 0.4874\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4602 - val_loss: 0.4873\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4599 - val_loss: 0.4868\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4595 - val_loss: 0.4866\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4591 - val_loss: 0.4865\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4588 - val_loss: 0.4861\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4584 - val_loss: 0.4858\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4580 - val_loss: 0.4855\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4577 - val_loss: 0.4853\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4574 - val_loss: 0.4850\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4570 - val_loss: 0.4848\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4567 - val_loss: 0.4847\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4563 - val_loss: 0.4844\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4559 - val_loss: 0.4841\n",
      "121/121 [==============================] - 0s 284us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 5.4139 - val_loss: 2.7862\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 2.0790 - val_loss: 1.8067\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 1.5630 - val_loss: 1.5907\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 1.4120 - val_loss: 1.4696\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.3266 - val_loss: 1.3808\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 1.2666 - val_loss: 1.3132\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.2204 - val_loss: 1.2693\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 1.1816 - val_loss: 1.2223\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 1.1447 - val_loss: 1.1806\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 1.1098 - val_loss: 1.1427\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 1.0762 - val_loss: 1.1066\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 1.0425 - val_loss: 1.0667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 1.0084 - val_loss: 1.0305\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.9762 - val_loss: 1.0005\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.9451 - val_loss: 0.9713\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.9159 - val_loss: 0.9399\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.8889 - val_loss: 0.9139\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.8646 - val_loss: 0.8843\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.8441 - val_loss: 0.8637\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.8253 - val_loss: 0.8425\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.8091 - val_loss: 0.8262\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.7948 - val_loss: 0.8091\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.7822 - val_loss: 0.7951\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.7705 - val_loss: 0.7803\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.7605 - val_loss: 0.7689\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.7511 - val_loss: 0.7595\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.7425 - val_loss: 0.7488\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.7341 - val_loss: 0.7401\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.7269 - val_loss: 0.7309\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.7197 - val_loss: 0.7230\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.7129 - val_loss: 0.7164\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.7068 - val_loss: 0.7094\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.7008 - val_loss: 0.7034\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6953 - val_loss: 0.6973\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6900 - val_loss: 0.6921\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6847 - val_loss: 0.6880\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6799 - val_loss: 0.6822\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6751 - val_loss: 0.6774\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6706 - val_loss: 0.6734\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6665 - val_loss: 0.6699\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.6622 - val_loss: 0.6665\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.6577 - val_loss: 0.6621\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.6543 - val_loss: 0.6590\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6502 - val_loss: 0.6560\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6465 - val_loss: 0.6529\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6428 - val_loss: 0.6505\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6397 - val_loss: 0.6473\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6361 - val_loss: 0.6454\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 480us/step - loss: 0.6333 - val_loss: 0.6422\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.6303 - val_loss: 0.6401\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6274 - val_loss: 0.6376\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.6245 - val_loss: 0.6354\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.6217 - val_loss: 0.6325\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6192 - val_loss: 0.6305\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6164 - val_loss: 0.6288\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6136 - val_loss: 0.6258\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6111 - val_loss: 0.6250\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6090 - val_loss: 0.6223\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6065 - val_loss: 0.6200\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.6042 - val_loss: 0.6180\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6017 - val_loss: 0.6157\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5996 - val_loss: 0.6142\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.5974 - val_loss: 0.6123\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.5952 - val_loss: 0.6106\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5931 - val_loss: 0.6094\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5909 - val_loss: 0.6078\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5887 - val_loss: 0.6058\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5867 - val_loss: 0.6035\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5846 - val_loss: 0.6016\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5826 - val_loss: 0.5997\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5804 - val_loss: 0.5980\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.5783 - val_loss: 0.5958\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5764 - val_loss: 0.5940\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5745 - val_loss: 0.5919\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5725 - val_loss: 0.5896\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5706 - val_loss: 0.5877\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5688 - val_loss: 0.5860\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5670 - val_loss: 0.5840\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.5651 - val_loss: 0.5817\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5632 - val_loss: 0.5797\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5616 - val_loss: 0.5781\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5597 - val_loss: 0.5762\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.5577 - val_loss: 0.5748\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5559 - val_loss: 0.5725\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.5540 - val_loss: 0.5709\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5519 - val_loss: 0.5684\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.5500 - val_loss: 0.5669\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.5480 - val_loss: 0.5651\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.5461 - val_loss: 0.5631\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5442 - val_loss: 0.5611\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5423 - val_loss: 0.5594\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.5404 - val_loss: 0.5574\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5385 - val_loss: 0.5557\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.5366 - val_loss: 0.5538\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5347 - val_loss: 0.5517\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5328 - val_loss: 0.5499\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5310 - val_loss: 0.5487\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5293 - val_loss: 0.5466\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5274 - val_loss: 0.5449\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5256 - val_loss: 0.5429\n",
      "121/121 [==============================] - 0s 278us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 624us/step - loss: 1.3488 - val_loss: 0.7487\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6836 - val_loss: 0.6480\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.6123 - val_loss: 0.5932\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.5642 - val_loss: 0.5561\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5309 - val_loss: 0.5316\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.5070 - val_loss: 0.5135\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4904 - val_loss: 0.5017\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4778 - val_loss: 0.4934\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4693 - val_loss: 0.4867\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4619 - val_loss: 0.4835\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4551 - val_loss: 0.4761\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4496 - val_loss: 0.4705\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.4449 - val_loss: 0.4691\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4406 - val_loss: 0.4629\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4366 - val_loss: 0.4623\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4331 - val_loss: 0.4575\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4292 - val_loss: 0.4553\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4263 - val_loss: 0.4529\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4231 - val_loss: 0.4548\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4209 - val_loss: 0.4477\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.4182 - val_loss: 0.4463\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4157 - val_loss: 0.4463\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4142 - val_loss: 0.4435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4118 - val_loss: 0.4437\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4109 - val_loss: 0.4397\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4085 - val_loss: 0.4407\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 514us/step - loss: 0.4068 - val_loss: 0.4369\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4032 - val_loss: 0.4332\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4020 - val_loss: 0.4333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4006 - val_loss: 0.4318\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3990 - val_loss: 0.4297\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3978 - val_loss: 0.4285\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3960 - val_loss: 0.4281\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3948 - val_loss: 0.4274\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3935 - val_loss: 0.4267\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3918 - val_loss: 0.4244\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3910 - val_loss: 0.4243\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3898 - val_loss: 0.4234\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3884 - val_loss: 0.4217\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3871 - val_loss: 0.4202\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3864 - val_loss: 0.4190\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3854 - val_loss: 0.4183\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3846 - val_loss: 0.4172\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3832 - val_loss: 0.4164\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3817 - val_loss: 0.4185\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3815 - val_loss: 0.4156\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3802 - val_loss: 0.4158\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3796 - val_loss: 0.4140\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3784 - val_loss: 0.4126\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3776 - val_loss: 0.4123\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3768 - val_loss: 0.4125\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3752 - val_loss: 0.4124\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3750 - val_loss: 0.4103\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3740 - val_loss: 0.4104\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3731 - val_loss: 0.4137\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3723 - val_loss: 0.4101\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3718 - val_loss: 0.4094\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3713 - val_loss: 0.4068\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3706 - val_loss: 0.4054\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3691 - val_loss: 0.4045\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3687 - val_loss: 0.4052\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3679 - val_loss: 0.4056\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3674 - val_loss: 0.4076\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3676 - val_loss: 0.4030\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3659 - val_loss: 0.4060\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3654 - val_loss: 0.4029\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3653 - val_loss: 0.4031\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3645 - val_loss: 0.4011\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3633 - val_loss: 0.4023\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3624 - val_loss: 0.4008\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3619 - val_loss: 0.4011\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3617 - val_loss: 0.4013\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3611 - val_loss: 0.3997\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3604 - val_loss: 0.4001\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3599 - val_loss: 0.4002\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3595 - val_loss: 0.3976\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3587 - val_loss: 0.3985\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3580 - val_loss: 0.3967\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3580 - val_loss: 0.3970\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3575 - val_loss: 0.3960\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3568 - val_loss: 0.3963\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3558 - val_loss: 0.3982\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3554 - val_loss: 0.3985\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3555 - val_loss: 0.3945\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3543 - val_loss: 0.3964\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3539 - val_loss: 0.3939\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3537 - val_loss: 0.3951\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3535 - val_loss: 0.3927\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3518 - val_loss: 0.3950\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3516 - val_loss: 0.3948\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3519 - val_loss: 0.3920\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3512 - val_loss: 0.3973\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3508 - val_loss: 0.3927\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3501 - val_loss: 0.3918\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3493 - val_loss: 0.3924\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3489 - val_loss: 0.3903\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3490 - val_loss: 0.3915\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3482 - val_loss: 0.3898\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3474 - val_loss: 0.3915\n",
      "121/121 [==============================] - 0s 275us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3660 - val_loss: 0.8353\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.7865 - val_loss: 0.7722\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.7308 - val_loss: 0.6202\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5815 - val_loss: 0.5776\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 445us/step - loss: 0.5302 - val_loss: 0.5492\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5059 - val_loss: 0.5300\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4879 - val_loss: 0.5126\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4728 - val_loss: 0.5020\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4612 - val_loss: 0.4906\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4527 - val_loss: 0.4850\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4444 - val_loss: 0.4762\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4383 - val_loss: 0.4705\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4336 - val_loss: 0.4674\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4288 - val_loss: 0.4629\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4252 - val_loss: 0.4631\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4215 - val_loss: 0.4553\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4187 - val_loss: 0.4538\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4155 - val_loss: 0.4503\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4128 - val_loss: 0.4515\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4101 - val_loss: 0.4484\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4097 - val_loss: 0.4440\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4065 - val_loss: 0.4423\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4051 - val_loss: 0.4409\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4034 - val_loss: 0.4400\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4005 - val_loss: 0.4369\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3973 - val_loss: 0.4416\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3971 - val_loss: 0.4338\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3950 - val_loss: 0.4333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3934 - val_loss: 0.4303\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3918 - val_loss: 0.4307\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3899 - val_loss: 0.4316\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3894 - val_loss: 0.4263\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3872 - val_loss: 0.4274\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3866 - val_loss: 0.4250\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3849 - val_loss: 0.4240\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3838 - val_loss: 0.4228\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3824 - val_loss: 0.4239\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3828 - val_loss: 0.4214\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3809 - val_loss: 0.4190\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3789 - val_loss: 0.4210\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3778 - val_loss: 0.4193\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3787 - val_loss: 0.4183\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3765 - val_loss: 0.4167\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3758 - val_loss: 0.4170\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3753 - val_loss: 0.4145\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.3761 - val_loss: 0.4140\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3738 - val_loss: 0.4163\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3766 - val_loss: 0.4125\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3712 - val_loss: 0.4126\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3715 - val_loss: 0.4111\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3702 - val_loss: 0.4117\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3702 - val_loss: 0.4118\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3713 - val_loss: 0.4109\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3735 - val_loss: 0.4121\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3665 - val_loss: 0.4084\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3657 - val_loss: 0.4097\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3639 - val_loss: 0.4077\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3632 - val_loss: 0.4098\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3628 - val_loss: 0.4046\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3620 - val_loss: 0.4050\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3607 - val_loss: 0.4038\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3602 - val_loss: 0.4051\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3602 - val_loss: 0.4039\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3593 - val_loss: 0.4095\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3598 - val_loss: 0.4017\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3573 - val_loss: 0.4024\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3572 - val_loss: 0.4005\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3570 - val_loss: 0.4066\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3566 - val_loss: 0.4014\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.3563 - val_loss: 0.4006\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.3556 - val_loss: 0.4011\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3570 - val_loss: 0.4030\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3555 - val_loss: 0.3987\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3557 - val_loss: 0.3967\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3527 - val_loss: 0.3975\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3520 - val_loss: 0.3975\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3521 - val_loss: 0.3970\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3514 - val_loss: 0.3967\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3516 - val_loss: 0.3959\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3551 - val_loss: 0.3961\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3507 - val_loss: 0.3948\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3518 - val_loss: 0.3952\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3484 - val_loss: 0.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3485 - val_loss: 0.3944\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3482 - val_loss: 0.3943\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3468 - val_loss: 0.3971\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3491 - val_loss: 0.3975\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3470 - val_loss: 0.3953\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3464 - val_loss: 0.3918\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3456 - val_loss: 0.3971\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3450 - val_loss: 0.3972\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3456 - val_loss: 0.3994\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.3445 - val_loss: 0.4002\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3447 - val_loss: 0.3938\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3453 - val_loss: 0.3965\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3433 - val_loss: 0.3910\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3434 - val_loss: 0.3918\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3448 - val_loss: 0.3977\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3434 - val_loss: 0.3905\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3429 - val_loss: 0.3943\n",
      "121/121 [==============================] - 0s 264us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 1.5772 - val_loss: 0.9786\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 1.4340 - val_loss: 1.3943\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.7219 - val_loss: 0.6346\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6119 - val_loss: 0.5807\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5637 - val_loss: 0.5427\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5322 - val_loss: 0.5197\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5100 - val_loss: 0.5065\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4951 - val_loss: 0.4937\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4842 - val_loss: 0.4844\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4744 - val_loss: 0.4779\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4684 - val_loss: 0.4723\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4626 - val_loss: 0.4680\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4568 - val_loss: 0.4639\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4522 - val_loss: 0.4602\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4479 - val_loss: 0.4594\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4442 - val_loss: 0.4523\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.4411 - val_loss: 0.4510\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4374 - val_loss: 0.4488\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4350 - val_loss: 0.4451\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4322 - val_loss: 0.4447\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4302 - val_loss: 0.4428\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4280 - val_loss: 0.4410\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4258 - val_loss: 0.4387\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4234 - val_loss: 0.4411\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4219 - val_loss: 0.4351\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4202 - val_loss: 0.4338\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4184 - val_loss: 0.4346\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4165 - val_loss: 0.4302\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4147 - val_loss: 0.4298\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4135 - val_loss: 0.4302\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4117 - val_loss: 0.4276\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4100 - val_loss: 0.4269\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4080 - val_loss: 0.4310\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4074 - val_loss: 0.4255\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4057 - val_loss: 0.4234\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4034 - val_loss: 0.4223\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4025 - val_loss: 0.4251\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4012 - val_loss: 0.4203\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3995 - val_loss: 0.4240\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3992 - val_loss: 0.4205\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3971 - val_loss: 0.4213\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3965 - val_loss: 0.4202\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3961 - val_loss: 0.4189\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3939 - val_loss: 0.4207\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3936 - val_loss: 0.4152\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3926 - val_loss: 0.4172\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3916 - val_loss: 0.4157\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3898 - val_loss: 0.4137\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3891 - val_loss: 0.4129\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3885 - val_loss: 0.4138\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3870 - val_loss: 0.4117\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3867 - val_loss: 0.4129\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3853 - val_loss: 0.4107\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3848 - val_loss: 0.4109\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3837 - val_loss: 0.4112\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3832 - val_loss: 0.4115\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3818 - val_loss: 0.4121\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3818 - val_loss: 0.4079\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.3806 - val_loss: 0.4081\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3801 - val_loss: 0.4066\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3787 - val_loss: 0.4064\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 456us/step - loss: 0.3782 - val_loss: 0.4078\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3776 - val_loss: 0.4067\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3770 - val_loss: 0.4057\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3763 - val_loss: 0.4050\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3756 - val_loss: 0.4049\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3746 - val_loss: 0.4030\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3743 - val_loss: 0.4053\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.3735 - val_loss: 0.4052\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3728 - val_loss: 0.4033\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3720 - val_loss: 0.4020\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3713 - val_loss: 0.4024\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3707 - val_loss: 0.4017\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3698 - val_loss: 0.4006\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3692 - val_loss: 0.4006\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3686 - val_loss: 0.3999\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3684 - val_loss: 0.3992\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3671 - val_loss: 0.4001\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3664 - val_loss: 0.3989\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3658 - val_loss: 0.3992\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3650 - val_loss: 0.3996\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3648 - val_loss: 0.3992\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3640 - val_loss: 0.3994\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3640 - val_loss: 0.3977\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3633 - val_loss: 0.3973\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3622 - val_loss: 0.3995\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3616 - val_loss: 0.3959\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3611 - val_loss: 0.3982\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3606 - val_loss: 0.3995\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3607 - val_loss: 0.3968\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3595 - val_loss: 0.3963\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3591 - val_loss: 0.4004\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3588 - val_loss: 0.3959\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3585 - val_loss: 0.3944\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3579 - val_loss: 0.3932\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3566 - val_loss: 0.3958\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.3567 - val_loss: 0.3952\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3565 - val_loss: 0.3932\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3558 - val_loss: 0.3938\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3554 - val_loss: 0.3963\n",
      "121/121 [==============================] - 0s 351us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.9620 - val_loss: 0.5644\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 591us/step - loss: 0.5096 - val_loss: 0.4844\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.4467 - val_loss: 0.4476\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4197 - val_loss: 0.4358\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4057 - val_loss: 0.4321\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3932 - val_loss: 0.4194\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3857 - val_loss: 0.4157\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3788 - val_loss: 0.4395\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3749 - val_loss: 0.4116\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3670 - val_loss: 0.4284\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.3623 - val_loss: 0.3975\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.3577 - val_loss: 0.3895\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.3555 - val_loss: 0.4150\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3500 - val_loss: 0.3895\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3468 - val_loss: 0.3928\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3446 - val_loss: 0.3818\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.3415 - val_loss: 0.3856\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3375 - val_loss: 0.3768\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3342 - val_loss: 0.3886\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3319 - val_loss: 0.3726\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3309 - val_loss: 0.3802\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3260 - val_loss: 0.3796\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3267 - val_loss: 0.3898\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3229 - val_loss: 0.3781\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3231 - val_loss: 0.3591\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3195 - val_loss: 0.3639\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3181 - val_loss: 0.3731\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3155 - val_loss: 0.3605\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3162 - val_loss: 0.3570\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3105 - val_loss: 0.3586\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3107 - val_loss: 0.3640\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3085 - val_loss: 0.3502\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3084 - val_loss: 0.3487\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3040 - val_loss: 0.3513\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3020 - val_loss: 0.3527\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3019 - val_loss: 0.3587\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3018 - val_loss: 0.3684\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3005 - val_loss: 0.3451\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2983 - val_loss: 0.3405\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 498us/step - loss: 0.2954 - val_loss: 0.3453\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2951 - val_loss: 0.3368\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2940 - val_loss: 0.3378\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2937 - val_loss: 0.3383\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.2918 - val_loss: 0.3522\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2929 - val_loss: 0.3394\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2934 - val_loss: 0.3369\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2896 - val_loss: 0.3313\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2893 - val_loss: 0.3299\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2887 - val_loss: 0.3351\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2883 - val_loss: 0.3373\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2865 - val_loss: 0.3352\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2846 - val_loss: 0.3366\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2823 - val_loss: 0.3369\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2838 - val_loss: 0.3341\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2816 - val_loss: 0.3344\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2824 - val_loss: 0.3299\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2828 - val_loss: 0.3334\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.2807 - val_loss: 0.3269\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2785 - val_loss: 0.3330\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2791 - val_loss: 0.3231\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2779 - val_loss: 0.3330\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2775 - val_loss: 0.3246\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2767 - val_loss: 0.3291\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2771 - val_loss: 0.3456\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2806 - val_loss: 0.3204\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2751 - val_loss: 0.3352\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2751 - val_loss: 0.3281\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2760 - val_loss: 0.3459\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2753 - val_loss: 0.3208\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2720 - val_loss: 0.3257\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2724 - val_loss: 0.3221\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2708 - val_loss: 0.3283\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2712 - val_loss: 0.3433\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2694 - val_loss: 0.3188\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2693 - val_loss: 0.3273\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.2702 - val_loss: 0.3498\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2676 - val_loss: 0.3266\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.2700 - val_loss: 0.3567\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.2679 - val_loss: 0.3450\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2691 - val_loss: 0.3218\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2676 - val_loss: 0.3291\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2703 - val_loss: 0.3246\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2696 - val_loss: 0.3195\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2646 - val_loss: 0.3572\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2636 - val_loss: 0.3172\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2626 - val_loss: 0.3192\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2624 - val_loss: 0.3294\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2666 - val_loss: 0.3244\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2619 - val_loss: 0.3274\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2610 - val_loss: 0.3209\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2599 - val_loss: 0.3289\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2635 - val_loss: 0.3217\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2603 - val_loss: 0.3208\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2621 - val_loss: 0.3220\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2590 - val_loss: 0.3208\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2596 - val_loss: 0.3371\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2596 - val_loss: 0.3148\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2616 - val_loss: 0.3161\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2585 - val_loss: 0.3148\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2588 - val_loss: 0.3384\n",
      "121/121 [==============================] - 0s 286us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.8305 - val_loss: 0.5542\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4914 - val_loss: 0.5023\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.4746 - val_loss: 0.4854\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4298 - val_loss: 0.4605\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4085 - val_loss: 0.4313\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3991 - val_loss: 0.4260\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.3923 - val_loss: 0.4257\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3819 - val_loss: 0.4187\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3772 - val_loss: 0.4122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3710 - val_loss: 0.4073\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3647 - val_loss: 0.4013\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3625 - val_loss: 0.3948\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3538 - val_loss: 0.3982\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.3512 - val_loss: 0.3941\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3471 - val_loss: 0.4062\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3444 - val_loss: 0.3830\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3392 - val_loss: 0.3804\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 522us/step - loss: 0.3343 - val_loss: 0.3752\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3313 - val_loss: 0.3790\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3308 - val_loss: 0.3804\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3262 - val_loss: 0.3699\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3257 - val_loss: 0.3862\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3331 - val_loss: 0.3852\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3351 - val_loss: 0.3744\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3211 - val_loss: 0.3650\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3130 - val_loss: 0.3695\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3151 - val_loss: 0.3851\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3113 - val_loss: 0.3591\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3112 - val_loss: 0.3612\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3074 - val_loss: 0.3683\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3066 - val_loss: 0.3621\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3047 - val_loss: 0.3502\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3041 - val_loss: 0.3628\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3041 - val_loss: 0.3528\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3005 - val_loss: 0.3502\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3022 - val_loss: 0.3537\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2956 - val_loss: 0.3555\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2972 - val_loss: 0.3444\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2964 - val_loss: 0.3510\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.2964 - val_loss: 0.3430\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2918 - val_loss: 0.3442\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2918 - val_loss: 0.3571\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2919 - val_loss: 0.3440\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2937 - val_loss: 0.3433\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2913 - val_loss: 0.3435\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2911 - val_loss: 0.3405\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2904 - val_loss: 0.3388\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2870 - val_loss: 0.3484\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2867 - val_loss: 0.3356\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2860 - val_loss: 0.3427\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.2860 - val_loss: 0.3375\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2838 - val_loss: 0.3392\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2819 - val_loss: 0.3431\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2849 - val_loss: 0.3444\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2810 - val_loss: 0.3366\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2800 - val_loss: 0.3316\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2802 - val_loss: 0.3355\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.2806 - val_loss: 0.3443\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2803 - val_loss: 0.3415\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2780 - val_loss: 0.3356\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2768 - val_loss: 0.3357\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2757 - val_loss: 0.3458\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2772 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2739 - val_loss: 0.3464\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2783 - val_loss: 0.3365\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2747 - val_loss: 0.3494\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2748 - val_loss: 0.3275\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2753 - val_loss: 0.3342\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2733 - val_loss: 0.3296\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2727 - val_loss: 0.3291\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2705 - val_loss: 0.3261\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2700 - val_loss: 0.3410\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2711 - val_loss: 0.3317\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2686 - val_loss: 0.3350\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2687 - val_loss: 0.3271\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2704 - val_loss: 0.3480\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2686 - val_loss: 0.3445\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2685 - val_loss: 0.3395\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2697 - val_loss: 0.3209\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2685 - val_loss: 0.3325\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2693 - val_loss: 0.3258\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2644 - val_loss: 0.3242\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2641 - val_loss: 0.3288\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2646 - val_loss: 0.3328\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2674 - val_loss: 0.3242\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2618 - val_loss: 0.3391\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2654 - val_loss: 0.3320\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2636 - val_loss: 0.3247\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2631 - val_loss: 0.3498\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2633 - val_loss: 0.3211\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2613 - val_loss: 0.3248\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2636 - val_loss: 0.3515\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2590 - val_loss: 0.3325\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2630 - val_loss: 0.3227\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2611 - val_loss: 0.3242\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2605 - val_loss: 0.3276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2600 - val_loss: 0.3189\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2596 - val_loss: 0.3319\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2597 - val_loss: 0.3239\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2597 - val_loss: 0.3339\n",
      "121/121 [==============================] - 0s 288us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 1.1521 - val_loss: 0.6345\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.5999 - val_loss: 0.6680\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.5334 - val_loss: 0.4793\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4506 - val_loss: 0.4438\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4145 - val_loss: 0.4287\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4017 - val_loss: 0.4198\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3914 - val_loss: 0.4110\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3843 - val_loss: 0.4071\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3774 - val_loss: 0.4050\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3710 - val_loss: 0.4034\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3686 - val_loss: 0.3980\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3650 - val_loss: 0.3951\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3601 - val_loss: 0.3876\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3575 - val_loss: 0.3884\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3539 - val_loss: 0.3967\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3505 - val_loss: 0.3823\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3483 - val_loss: 0.3858\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3437 - val_loss: 0.3731\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3436 - val_loss: 0.3703\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3416 - val_loss: 0.3765\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3379 - val_loss: 0.3834\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3352 - val_loss: 0.3663\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3335 - val_loss: 0.3690\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3308 - val_loss: 0.3757\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3274 - val_loss: 0.3710\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3265 - val_loss: 0.3613\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3241 - val_loss: 0.3736\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3241 - val_loss: 0.3622\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3192 - val_loss: 0.3615\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3179 - val_loss: 0.3576\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3187 - val_loss: 0.3567\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3167 - val_loss: 0.3616\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3127 - val_loss: 0.3555\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3114 - val_loss: 0.3560\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3102 - val_loss: 0.3672\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3105 - val_loss: 0.3487\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3058 - val_loss: 0.3857\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3061 - val_loss: 0.3464\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3043 - val_loss: 0.3593\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3039 - val_loss: 0.3459\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3007 - val_loss: 0.3459\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.3025 - val_loss: 0.3861\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3002 - val_loss: 0.3625\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2982 - val_loss: 0.3611\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2982 - val_loss: 0.3449\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2965 - val_loss: 0.3450\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2958 - val_loss: 0.3492\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.2940 - val_loss: 0.3539\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2931 - val_loss: 0.3384\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2926 - val_loss: 0.3376\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2898 - val_loss: 0.3377\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.2895 - val_loss: 0.3447\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2877 - val_loss: 0.3371\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.2867 - val_loss: 0.3465\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2861 - val_loss: 0.3433\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2856 - val_loss: 0.3381\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.2840 - val_loss: 0.3387\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2869 - val_loss: 0.3391\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2838 - val_loss: 0.3459\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2821 - val_loss: 0.3432\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2835 - val_loss: 0.3329\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2801 - val_loss: 0.3417\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2811 - val_loss: 0.3356\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2802 - val_loss: 0.3343\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2775 - val_loss: 0.3502\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2784 - val_loss: 0.3403\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2759 - val_loss: 0.3301\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2760 - val_loss: 0.3323\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2739 - val_loss: 0.3334\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2739 - val_loss: 0.3350\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2735 - val_loss: 0.3290\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2738 - val_loss: 0.3529\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2737 - val_loss: 0.3290\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2715 - val_loss: 0.3369\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 490us/step - loss: 0.2718 - val_loss: 0.3391\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2717 - val_loss: 0.3292\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2698 - val_loss: 0.3301\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2720 - val_loss: 0.3311\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2707 - val_loss: 0.3210\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.2667 - val_loss: 0.3424\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2680 - val_loss: 0.3245\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2657 - val_loss: 0.3447\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2644 - val_loss: 0.3284\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2669 - val_loss: 0.3329\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2664 - val_loss: 0.3224\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2644 - val_loss: 0.3357\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2656 - val_loss: 0.3266\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.2632 - val_loss: 0.3207\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2622 - val_loss: 0.3425\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.2644 - val_loss: 0.3249\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2621 - val_loss: 0.3369\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2636 - val_loss: 0.3390\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2622 - val_loss: 0.3293\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2633 - val_loss: 0.3264\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2584 - val_loss: 0.3316\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2608 - val_loss: 0.3258\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2587 - val_loss: 0.3227\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2593 - val_loss: 0.3237\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2598 - val_loss: 0.3161\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2606 - val_loss: 0.3200\n",
      "121/121 [==============================] - 0s 286us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 628us/step - loss: 2.9967 - val_loss: 1.5764\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 1.1781 - val_loss: 1.0151\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.8969 - val_loss: 0.8789\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.8122 - val_loss: 0.8211\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.7680 - val_loss: 0.7837\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.7363 - val_loss: 0.7549\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.7109 - val_loss: 0.7304\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6891 - val_loss: 0.7094\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.6702 - val_loss: 0.6913\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.6536 - val_loss: 0.6751\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6386 - val_loss: 0.6602\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.6251 - val_loss: 0.6470\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6129 - val_loss: 0.6352\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.6017 - val_loss: 0.6241\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5915 - val_loss: 0.6143\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5820 - val_loss: 0.6056\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5732 - val_loss: 0.5972\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5653 - val_loss: 0.5898\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5576 - val_loss: 0.5840\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5510 - val_loss: 0.5768\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5444 - val_loss: 0.5706\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5384 - val_loss: 0.5660\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5329 - val_loss: 0.5607\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5278 - val_loss: 0.5563\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5233 - val_loss: 0.5531\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5191 - val_loss: 0.5486\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5152 - val_loss: 0.5449\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5116 - val_loss: 0.5421\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5082 - val_loss: 0.5394\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5053 - val_loss: 0.5365\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5024 - val_loss: 0.5340\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4996 - val_loss: 0.5312\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4971 - val_loss: 0.5307\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4947 - val_loss: 0.5277\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4925 - val_loss: 0.5246\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4904 - val_loss: 0.5236\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4884 - val_loss: 0.5235\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4867 - val_loss: 0.5210\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4849 - val_loss: 0.5188\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4833 - val_loss: 0.5162\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4815 - val_loss: 0.5144\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4802 - val_loss: 0.5140\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4789 - val_loss: 0.5118\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4773 - val_loss: 0.5133\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4761 - val_loss: 0.5108\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4750 - val_loss: 0.5098\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4740 - val_loss: 0.5076\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4726 - val_loss: 0.5054\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4717 - val_loss: 0.5041\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4705 - val_loss: 0.5043\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4692 - val_loss: 0.5014\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4687 - val_loss: 0.5022\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 445us/step - loss: 0.4676 - val_loss: 0.4999\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4665 - val_loss: 0.4993\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4653 - val_loss: 0.4983\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4644 - val_loss: 0.4978\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4636 - val_loss: 0.4980\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4627 - val_loss: 0.4970\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4618 - val_loss: 0.4952\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4608 - val_loss: 0.4937\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4600 - val_loss: 0.4925\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4592 - val_loss: 0.4926\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4584 - val_loss: 0.4910\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4576 - val_loss: 0.4918\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4568 - val_loss: 0.4914\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4559 - val_loss: 0.4889\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4554 - val_loss: 0.4899\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4547 - val_loss: 0.4877\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4538 - val_loss: 0.4875\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4531 - val_loss: 0.4874\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4524 - val_loss: 0.4873\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4516 - val_loss: 0.4850\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4508 - val_loss: 0.4840\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4500 - val_loss: 0.4867\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4499 - val_loss: 0.4839\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4488 - val_loss: 0.4836\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4484 - val_loss: 0.4834\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4478 - val_loss: 0.4814\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4471 - val_loss: 0.4803\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4465 - val_loss: 0.4811\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4457 - val_loss: 0.4804\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4450 - val_loss: 0.4808\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4445 - val_loss: 0.4793\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4439 - val_loss: 0.4782\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4432 - val_loss: 0.4778\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4422 - val_loss: 0.4760\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4419 - val_loss: 0.4759\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4414 - val_loss: 0.4751\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4408 - val_loss: 0.4758\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4400 - val_loss: 0.4753\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4396 - val_loss: 0.4748\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4389 - val_loss: 0.4740\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4384 - val_loss: 0.4746\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4378 - val_loss: 0.4729\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4372 - val_loss: 0.4730\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4366 - val_loss: 0.4710\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4358 - val_loss: 0.4724\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4354 - val_loss: 0.4705\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4349 - val_loss: 0.4706\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4342 - val_loss: 0.4693\n",
      "121/121 [==============================] - 0s 270us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 628us/step - loss: 2.3582 - val_loss: 1.1780\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.8618 - val_loss: 0.7662\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.7054 - val_loss: 0.7112\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.6700 - val_loss: 0.6884\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.6502 - val_loss: 0.6727\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.6340 - val_loss: 0.6559\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.6194 - val_loss: 0.6419\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.6067 - val_loss: 0.6299\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5950 - val_loss: 0.6189\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5851 - val_loss: 0.6086\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5748 - val_loss: 0.5987\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5661 - val_loss: 0.5896\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5576 - val_loss: 0.5821\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5505 - val_loss: 0.5740\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5425 - val_loss: 0.5675\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5364 - val_loss: 0.5601\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5297 - val_loss: 0.5542\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5237 - val_loss: 0.5489\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5178 - val_loss: 0.5437\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5121 - val_loss: 0.5396\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5089 - val_loss: 0.5339\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5032 - val_loss: 0.5298\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4995 - val_loss: 0.5262\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4967 - val_loss: 0.5222\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4919 - val_loss: 0.5190\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4889 - val_loss: 0.5166\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4859 - val_loss: 0.5139\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4833 - val_loss: 0.5120\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4809 - val_loss: 0.5100\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4789 - val_loss: 0.5081\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 448us/step - loss: 0.4772 - val_loss: 0.5064\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4752 - val_loss: 0.5045\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4732 - val_loss: 0.5032\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4722 - val_loss: 0.5016\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4707 - val_loss: 0.5004\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4695 - val_loss: 0.4989\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4682 - val_loss: 0.4978\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4674 - val_loss: 0.4964\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4661 - val_loss: 0.4954\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4653 - val_loss: 0.4942\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4640 - val_loss: 0.4940\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4632 - val_loss: 0.4926\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4623 - val_loss: 0.4917\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4614 - val_loss: 0.4909\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4603 - val_loss: 0.4896\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4595 - val_loss: 0.4883\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4587 - val_loss: 0.4880\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4577 - val_loss: 0.4874\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4568 - val_loss: 0.4860\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4559 - val_loss: 0.4849\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4551 - val_loss: 0.4845\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4542 - val_loss: 0.4844\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4542 - val_loss: 0.4830\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4530 - val_loss: 0.4822\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4517 - val_loss: 0.4826\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4509 - val_loss: 0.4810\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4501 - val_loss: 0.4813\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4494 - val_loss: 0.4799\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4492 - val_loss: 0.4791\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4488 - val_loss: 0.4784\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4472 - val_loss: 0.4779\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4466 - val_loss: 0.4771\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4461 - val_loss: 0.4767\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4454 - val_loss: 0.4753\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4450 - val_loss: 0.4751\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4444 - val_loss: 0.4749\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4437 - val_loss: 0.4740\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4436 - val_loss: 0.4737\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4437 - val_loss: 0.4731\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4425 - val_loss: 0.4727\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4422 - val_loss: 0.4716\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4413 - val_loss: 0.4719\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4412 - val_loss: 0.4713\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4404 - val_loss: 0.4703\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4400 - val_loss: 0.4708\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4399 - val_loss: 0.4698\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4391 - val_loss: 0.4688\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4386 - val_loss: 0.4696\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4389 - val_loss: 0.4681\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4385 - val_loss: 0.4680\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4374 - val_loss: 0.4674\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4369 - val_loss: 0.4671\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4365 - val_loss: 0.4666\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4362 - val_loss: 0.4660\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4358 - val_loss: 0.4658\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4352 - val_loss: 0.4662\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4351 - val_loss: 0.4655\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4345 - val_loss: 0.4652\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4340 - val_loss: 0.4641\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4335 - val_loss: 0.4640\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4330 - val_loss: 0.4634\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4329 - val_loss: 0.4629\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4322 - val_loss: 0.4615\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4316 - val_loss: 0.4622\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4318 - val_loss: 0.4605\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4306 - val_loss: 0.4604\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4304 - val_loss: 0.4593\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4301 - val_loss: 0.4596\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4294 - val_loss: 0.4585\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4289 - val_loss: 0.4582\n",
      "121/121 [==============================] - 0s 270us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 3.1501 - val_loss: 1.5383\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 1.1483 - val_loss: 0.8229\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.7798 - val_loss: 0.6938\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.7013 - val_loss: 0.6688\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.6724 - val_loss: 0.6530\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.6536 - val_loss: 0.6388\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.6374 - val_loss: 0.6257\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.6227 - val_loss: 0.6111\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 444us/step - loss: 0.6092 - val_loss: 0.5989\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5962 - val_loss: 0.5877\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5844 - val_loss: 0.5769\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.5733 - val_loss: 0.5668\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5632 - val_loss: 0.5585\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5540 - val_loss: 0.5507\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5453 - val_loss: 0.5431\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5379 - val_loss: 0.5379\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5312 - val_loss: 0.5309\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5250 - val_loss: 0.5254\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5197 - val_loss: 0.5210\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5150 - val_loss: 0.5190\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5110 - val_loss: 0.5147\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5072 - val_loss: 0.5119\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5039 - val_loss: 0.5083\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5008 - val_loss: 0.5069\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.4982 - val_loss: 0.5037\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4958 - val_loss: 0.5024\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4936 - val_loss: 0.5001\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4916 - val_loss: 0.4990\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4898 - val_loss: 0.4977\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4881 - val_loss: 0.4954\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4864 - val_loss: 0.4936\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4850 - val_loss: 0.4929\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4833 - val_loss: 0.4907\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4822 - val_loss: 0.4897\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4808 - val_loss: 0.4887\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4794 - val_loss: 0.4879\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4783 - val_loss: 0.4870\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4769 - val_loss: 0.4863\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4760 - val_loss: 0.4845\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4749 - val_loss: 0.4832\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4739 - val_loss: 0.4830\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4728 - val_loss: 0.4820\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4719 - val_loss: 0.4807\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4708 - val_loss: 0.4804\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4699 - val_loss: 0.4794\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4689 - val_loss: 0.4783\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4683 - val_loss: 0.4777\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4671 - val_loss: 0.4770\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4663 - val_loss: 0.4763\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4655 - val_loss: 0.4754\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4646 - val_loss: 0.4748\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4638 - val_loss: 0.4740\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4628 - val_loss: 0.4730\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4620 - val_loss: 0.4723\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4612 - val_loss: 0.4719\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4604 - val_loss: 0.4707\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4595 - val_loss: 0.4708\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4588 - val_loss: 0.4695\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4581 - val_loss: 0.4690\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4573 - val_loss: 0.4680\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4564 - val_loss: 0.4675\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4558 - val_loss: 0.4672\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4551 - val_loss: 0.4663\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4543 - val_loss: 0.4653\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4536 - val_loss: 0.4644\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4529 - val_loss: 0.4642\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4522 - val_loss: 0.4632\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4515 - val_loss: 0.4626\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4508 - val_loss: 0.4621\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4500 - val_loss: 0.4613\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4495 - val_loss: 0.4607\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4487 - val_loss: 0.4602\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4480 - val_loss: 0.4597\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4474 - val_loss: 0.4590\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4468 - val_loss: 0.4582\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4460 - val_loss: 0.4582\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.4455 - val_loss: 0.4570\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.4448 - val_loss: 0.4572\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4441 - val_loss: 0.4561\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.4436 - val_loss: 0.4556\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4430 - val_loss: 0.4546\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.4423 - val_loss: 0.4543\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.4417 - val_loss: 0.4542\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4411 - val_loss: 0.4535\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4405 - val_loss: 0.4530\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.4399 - val_loss: 0.4527\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4393 - val_loss: 0.4518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4387 - val_loss: 0.4516\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4381 - val_loss: 0.4514\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.4377 - val_loss: 0.4502\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4370 - val_loss: 0.4496\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4364 - val_loss: 0.4496\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4358 - val_loss: 0.4488\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4354 - val_loss: 0.4484\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4348 - val_loss: 0.4481\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4341 - val_loss: 0.4484\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.4339 - val_loss: 0.4473\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4333 - val_loss: 0.4464\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4327 - val_loss: 0.4458\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4320 - val_loss: 0.4463\n",
      "121/121 [==============================] - 0s 271us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.8990 - val_loss: 0.5945\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5416 - val_loss: 0.5191\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4852 - val_loss: 0.4749\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4518 - val_loss: 0.4548\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4344 - val_loss: 0.4472\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4187 - val_loss: 0.4278\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4103 - val_loss: 0.4265\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4001 - val_loss: 0.4546\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3959 - val_loss: 0.4179\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3858 - val_loss: 0.4292\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.3795 - val_loss: 0.4063\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.3724 - val_loss: 0.3999\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3696 - val_loss: 0.4268\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.3618 - val_loss: 0.4007\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.3580 - val_loss: 0.4045\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3543 - val_loss: 0.3877\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3491 - val_loss: 0.3856\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3445 - val_loss: 0.3802\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3398 - val_loss: 0.3923\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3361 - val_loss: 0.3732\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3341 - val_loss: 0.3888\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3281 - val_loss: 0.3830\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3279 - val_loss: 0.3964\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3235 - val_loss: 0.3814\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3237 - val_loss: 0.3612\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.3193 - val_loss: 0.3710\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3180 - val_loss: 0.3667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3145 - val_loss: 0.3649\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3141 - val_loss: 0.3569\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3079 - val_loss: 0.3636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3093 - val_loss: 0.3695\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3060 - val_loss: 0.3621\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3072 - val_loss: 0.3525\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3029 - val_loss: 0.3498\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3001 - val_loss: 0.3554\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3004 - val_loss: 0.3593\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2994 - val_loss: 0.3693\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2976 - val_loss: 0.3437\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2954 - val_loss: 0.3413\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2936 - val_loss: 0.3514\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2929 - val_loss: 0.3386\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2911 - val_loss: 0.3361\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2922 - val_loss: 0.3396\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2907 - val_loss: 0.3595\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2916 - val_loss: 0.3381\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2910 - val_loss: 0.3490\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2881 - val_loss: 0.3320\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2872 - val_loss: 0.3329\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2860 - val_loss: 0.3394\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2858 - val_loss: 0.3347\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2850 - val_loss: 0.3574\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2956 - val_loss: 0.3381\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2803 - val_loss: 0.3574\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2820 - val_loss: 0.3382\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2794 - val_loss: 0.3320\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2793 - val_loss: 0.3312\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2803 - val_loss: 0.3388\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2785 - val_loss: 0.3288\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2767 - val_loss: 0.3442\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2778 - val_loss: 0.3316\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2754 - val_loss: 0.3341\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2757 - val_loss: 0.3236\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2751 - val_loss: 0.3437\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2785 - val_loss: 0.3474\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2808 - val_loss: 0.3224\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 485us/step - loss: 0.2734 - val_loss: 0.3337\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2735 - val_loss: 0.3397\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2762 - val_loss: 0.3373\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2725 - val_loss: 0.3322\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2750 - val_loss: 0.3297\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2713 - val_loss: 0.3356\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2731 - val_loss: 0.3297\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2685 - val_loss: 0.3481\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2696 - val_loss: 0.3494\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.2713 - val_loss: 0.3389\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2703 - val_loss: 0.3550\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2671 - val_loss: 0.3387\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2675 - val_loss: 0.3458\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2674 - val_loss: 0.3479\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2678 - val_loss: 0.3295\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2673 - val_loss: 0.3330\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2666 - val_loss: 0.3216\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2668 - val_loss: 0.3270\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2652 - val_loss: 0.3575\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2654 - val_loss: 0.3209\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2633 - val_loss: 0.3287\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2634 - val_loss: 0.3384\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2666 - val_loss: 0.3248\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2633 - val_loss: 0.3396\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2627 - val_loss: 0.3238\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2628 - val_loss: 0.3281\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.2643 - val_loss: 0.3278\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2610 - val_loss: 0.3405\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2645 - val_loss: 0.3274\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2616 - val_loss: 0.3382\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2663 - val_loss: 0.3237\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2623 - val_loss: 0.3497\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2634 - val_loss: 0.3211\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.2611 - val_loss: 0.3357\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2633 - val_loss: 0.3377\n",
      "121/121 [==============================] - 0s 284us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.9027 - val_loss: 0.5908\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5050 - val_loss: 0.4890\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.4408 - val_loss: 0.4748\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4354 - val_loss: 0.4749\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.4441 - val_loss: 0.4373\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4067 - val_loss: 0.4422\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4011 - val_loss: 0.4267\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3853 - val_loss: 0.4161\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3790 - val_loss: 0.4123\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.3729 - val_loss: 0.4023\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3674 - val_loss: 0.3985\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3629 - val_loss: 0.3935\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3561 - val_loss: 0.3977\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3517 - val_loss: 0.3927\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3497 - val_loss: 0.3917\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3440 - val_loss: 0.3835\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3405 - val_loss: 0.3783\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3350 - val_loss: 0.3755\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3329 - val_loss: 0.3761\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3303 - val_loss: 0.3779\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3290 - val_loss: 0.3667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3259 - val_loss: 0.3694\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3241 - val_loss: 0.3833\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3196 - val_loss: 0.3649\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3195 - val_loss: 0.3637\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3124 - val_loss: 0.3719\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3146 - val_loss: 0.3880\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.3122 - val_loss: 0.3614\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3120 - val_loss: 0.3604\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3081 - val_loss: 0.3608\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3072 - val_loss: 0.3619\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3066 - val_loss: 0.3506\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3060 - val_loss: 0.3587\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3044 - val_loss: 0.3517\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3028 - val_loss: 0.3476\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3038 - val_loss: 0.3533\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2980 - val_loss: 0.3554\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2983 - val_loss: 0.3441\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2982 - val_loss: 0.3479\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2970 - val_loss: 0.3411\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2932 - val_loss: 0.3411\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2936 - val_loss: 0.3608\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2942 - val_loss: 0.3427\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 492us/step - loss: 0.2950 - val_loss: 0.3443\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2924 - val_loss: 0.3387\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.2927 - val_loss: 0.3407\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2910 - val_loss: 0.3386\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2889 - val_loss: 0.3488\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2877 - val_loss: 0.3329\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2873 - val_loss: 0.3425\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2864 - val_loss: 0.3379\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2851 - val_loss: 0.3384\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2832 - val_loss: 0.3365\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2846 - val_loss: 0.3531\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2838 - val_loss: 0.3352\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2825 - val_loss: 0.3319\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2809 - val_loss: 0.3318\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2826 - val_loss: 0.3308\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2817 - val_loss: 0.3461\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2795 - val_loss: 0.3283\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2783 - val_loss: 0.3335\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2773 - val_loss: 0.3393\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2788 - val_loss: 0.3285\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2754 - val_loss: 0.3450\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.2841 - val_loss: 0.3357\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2756 - val_loss: 0.3493\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2765 - val_loss: 0.3273\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.2765 - val_loss: 0.3311\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2750 - val_loss: 0.3322\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.2743 - val_loss: 0.3237\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.2730 - val_loss: 0.3231\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2720 - val_loss: 0.3318\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.2725 - val_loss: 0.3267\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.2710 - val_loss: 0.3360\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.2702 - val_loss: 0.3252\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2721 - val_loss: 0.3340\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2703 - val_loss: 0.3379\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2703 - val_loss: 0.3356\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2706 - val_loss: 0.3182\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2690 - val_loss: 0.3331\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.2707 - val_loss: 0.3218\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2673 - val_loss: 0.3192\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2654 - val_loss: 0.3221\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2669 - val_loss: 0.3270\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2686 - val_loss: 0.3218\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2642 - val_loss: 0.3359\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2654 - val_loss: 0.3258\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2652 - val_loss: 0.3231\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2651 - val_loss: 0.3697\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2649 - val_loss: 0.3244\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2634 - val_loss: 0.3240\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2653 - val_loss: 0.3470\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2615 - val_loss: 0.3219\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2638 - val_loss: 0.3210\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2630 - val_loss: 0.3191\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.2625 - val_loss: 0.3257\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2611 - val_loss: 0.3198\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2601 - val_loss: 0.3258\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2615 - val_loss: 0.3250\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2617 - val_loss: 0.3347\n",
      "121/121 [==============================] - 0s 285us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 1.4778 - val_loss: 0.7988\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.7111 - val_loss: 0.6334\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6144 - val_loss: 0.5098\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4703 - val_loss: 0.4687\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4381 - val_loss: 0.4478\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4198 - val_loss: 0.4327\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4063 - val_loss: 0.4205\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3961 - val_loss: 0.4131\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3867 - val_loss: 0.4107\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3808 - val_loss: 0.4069\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3763 - val_loss: 0.4001\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3724 - val_loss: 0.3997\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3654 - val_loss: 0.3943\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3609 - val_loss: 0.3926\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3566 - val_loss: 0.4003\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3523 - val_loss: 0.3840\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3485 - val_loss: 0.3953\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3421 - val_loss: 0.3748\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3415 - val_loss: 0.3688\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3398 - val_loss: 0.3760\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3366 - val_loss: 0.3850\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 487us/step - loss: 0.3316 - val_loss: 0.3666\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3282 - val_loss: 0.4082\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3304 - val_loss: 0.3710\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3214 - val_loss: 0.3681\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3217 - val_loss: 0.3597\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3202 - val_loss: 0.3696\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3184 - val_loss: 0.3567\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3146 - val_loss: 0.3674\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3135 - val_loss: 0.3540\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3147 - val_loss: 0.3839\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3138 - val_loss: 0.3559\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3103 - val_loss: 0.3501\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3099 - val_loss: 0.3512\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3073 - val_loss: 0.3707\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3082 - val_loss: 0.3432\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3044 - val_loss: 0.4039\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3047 - val_loss: 0.3397\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3030 - val_loss: 0.3493\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3031 - val_loss: 0.3428\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3001 - val_loss: 0.3392\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3016 - val_loss: 0.3749\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2991 - val_loss: 0.3756\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2986 - val_loss: 0.3546\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.2976 - val_loss: 0.3400\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2996 - val_loss: 0.3433\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2957 - val_loss: 0.3481\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2961 - val_loss: 0.3472\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2946 - val_loss: 0.3336\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2941 - val_loss: 0.3365\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2906 - val_loss: 0.3360\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2917 - val_loss: 0.3441\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.2936 - val_loss: 0.3342\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2900 - val_loss: 0.3463\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.2892 - val_loss: 0.3411\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2889 - val_loss: 0.3425\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2862 - val_loss: 0.3382\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2890 - val_loss: 0.3330\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2880 - val_loss: 0.3368\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2863 - val_loss: 0.3441\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2883 - val_loss: 0.3328\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2842 - val_loss: 0.3369\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.2854 - val_loss: 0.3325\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2852 - val_loss: 0.3339\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2818 - val_loss: 0.3560\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2832 - val_loss: 0.3346\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.2849 - val_loss: 0.3717\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2831 - val_loss: 0.3356\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2814 - val_loss: 0.3331\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2814 - val_loss: 0.3356\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2802 - val_loss: 0.3270\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.2793 - val_loss: 0.3800\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.2808 - val_loss: 0.3230\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2784 - val_loss: 0.3305\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2791 - val_loss: 0.3350\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2781 - val_loss: 0.3284\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2771 - val_loss: 0.3335\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2772 - val_loss: 0.3473\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2775 - val_loss: 0.3197\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2755 - val_loss: 0.3409\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2768 - val_loss: 0.3305\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2748 - val_loss: 0.3702\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2731 - val_loss: 0.3220\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2755 - val_loss: 0.3449\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.2730 - val_loss: 0.3273\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2720 - val_loss: 0.3454\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2726 - val_loss: 0.3327\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2703 - val_loss: 0.3234\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2703 - val_loss: 0.3293\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.2713 - val_loss: 0.3252\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2705 - val_loss: 0.3409\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2706 - val_loss: 0.3411\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.2696 - val_loss: 0.3385\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2702 - val_loss: 0.3302\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2685 - val_loss: 0.3250\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.2676 - val_loss: 0.3269\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2670 - val_loss: 0.3205\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2674 - val_loss: 0.3235\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.2667 - val_loss: 0.3162\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.2676 - val_loss: 0.3280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 281us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.9385 - val_loss: 0.6047\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5311 - val_loss: 0.4958\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4570 - val_loss: 0.4598\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.4273 - val_loss: 0.4485\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4131 - val_loss: 0.4400\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4001 - val_loss: 0.4258\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3915 - val_loss: 0.4193\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3819 - val_loss: 0.4607\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3781 - val_loss: 0.4101\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3689 - val_loss: 0.4325\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3627 - val_loss: 0.4012\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3571 - val_loss: 0.3900\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3544 - val_loss: 0.4333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3471 - val_loss: 0.3958\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3439 - val_loss: 0.4100\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3415 - val_loss: 0.3799\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3364 - val_loss: 0.3790\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3320 - val_loss: 0.3738\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3279 - val_loss: 0.3844\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3256 - val_loss: 0.3647\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3229 - val_loss: 0.3754\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3171 - val_loss: 0.3730\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3177 - val_loss: 0.3897\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3149 - val_loss: 0.3655\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3149 - val_loss: 0.3519\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3111 - val_loss: 0.3597\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3098 - val_loss: 0.3642\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3068 - val_loss: 0.3559\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3067 - val_loss: 0.3486\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3008 - val_loss: 0.3493\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3021 - val_loss: 0.3623\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2982 - val_loss: 0.3474\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2995 - val_loss: 0.3413\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.2949 - val_loss: 0.3429\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2930 - val_loss: 0.3455\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2924 - val_loss: 0.3540\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2926 - val_loss: 0.3640\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2918 - val_loss: 0.3350\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2895 - val_loss: 0.3321\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2873 - val_loss: 0.3396\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2865 - val_loss: 0.3317\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2848 - val_loss: 0.3299\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2856 - val_loss: 0.3320\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2831 - val_loss: 0.3457\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2841 - val_loss: 0.3264\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2836 - val_loss: 0.3341\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2823 - val_loss: 0.3235\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2814 - val_loss: 0.3232\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2798 - val_loss: 0.3252\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2800 - val_loss: 0.3262\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2768 - val_loss: 0.3294\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.2777 - val_loss: 0.3277\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2726 - val_loss: 0.3344\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2744 - val_loss: 0.3277\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.2727 - val_loss: 0.3256\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.2736 - val_loss: 0.3240\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.2735 - val_loss: 0.3260\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.2734 - val_loss: 0.3204\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.2700 - val_loss: 0.3355\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.2716 - val_loss: 0.3173\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.2693 - val_loss: 0.3285\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.2702 - val_loss: 0.3172\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.2677 - val_loss: 0.3250\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.2693 - val_loss: 0.3574\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.2770 - val_loss: 0.3132\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.2682 - val_loss: 0.3243\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2669 - val_loss: 0.3329\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2717 - val_loss: 0.3375\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.2672 - val_loss: 0.3208\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2666 - val_loss: 0.3150\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2649 - val_loss: 0.3264\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2668 - val_loss: 0.3198\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2639 - val_loss: 0.3514\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.2640 - val_loss: 0.3108\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2617 - val_loss: 0.3459\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2635 - val_loss: 0.3547\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.2605 - val_loss: 0.3266\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2610 - val_loss: 0.3416\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 731us/step - loss: 0.2607 - val_loss: 0.3442\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2612 - val_loss: 0.3194\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.2607 - val_loss: 0.3186\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2589 - val_loss: 0.3110\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2597 - val_loss: 0.3184\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2570 - val_loss: 0.3411\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2569 - val_loss: 0.3109\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2563 - val_loss: 0.3154\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2555 - val_loss: 0.3315\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.2597 - val_loss: 0.3170\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2551 - val_loss: 0.3301\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2549 - val_loss: 0.3117\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.2545 - val_loss: 0.3172\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2554 - val_loss: 0.3190\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2534 - val_loss: 0.3384\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2557 - val_loss: 0.3153\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2536 - val_loss: 0.3262\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2584 - val_loss: 0.3304\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2522 - val_loss: 0.3276\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2556 - val_loss: 0.3126\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.2519 - val_loss: 0.3131\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.2527 - val_loss: 0.3264\n",
      "121/121 [==============================] - 0s 285us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.8548 - val_loss: 0.5879\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5135 - val_loss: 0.5237\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4920 - val_loss: 0.4803\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4301 - val_loss: 0.4578\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.4098 - val_loss: 0.4299\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.3999 - val_loss: 0.4225\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3925 - val_loss: 0.4234\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3829 - val_loss: 0.4210\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3782 - val_loss: 0.4128\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3728 - val_loss: 0.4069\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3669 - val_loss: 0.4010\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.3635 - val_loss: 0.3942\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3560 - val_loss: 0.3973\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.3538 - val_loss: 0.3928\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3487 - val_loss: 0.4000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3480 - val_loss: 0.3849\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3409 - val_loss: 0.3783\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.3350 - val_loss: 0.3750\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3324 - val_loss: 0.3750\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.3297 - val_loss: 0.3809\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3281 - val_loss: 0.3677\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3251 - val_loss: 0.3716\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.3240 - val_loss: 0.3787\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3182 - val_loss: 0.3617\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3142 - val_loss: 0.3603\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3088 - val_loss: 0.3691\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3090 - val_loss: 0.3779\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3067 - val_loss: 0.3546\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3060 - val_loss: 0.3593\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3031 - val_loss: 0.3577\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2995 - val_loss: 0.3553\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2990 - val_loss: 0.3423\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2979 - val_loss: 0.3580\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2994 - val_loss: 0.3421\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2926 - val_loss: 0.3434\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.2954 - val_loss: 0.3478\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2890 - val_loss: 0.3501\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2915 - val_loss: 0.3356\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.2889 - val_loss: 0.3429\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.2887 - val_loss: 0.3338\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.2837 - val_loss: 0.3368\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2838 - val_loss: 0.3553\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.2845 - val_loss: 0.3359\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2871 - val_loss: 0.3463\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2864 - val_loss: 0.3380\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2836 - val_loss: 0.3379\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.2810 - val_loss: 0.3344\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.2797 - val_loss: 0.3436\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.2774 - val_loss: 0.3302\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.2780 - val_loss: 0.3381\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.2764 - val_loss: 0.3318\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2747 - val_loss: 0.3371\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2721 - val_loss: 0.3345\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2766 - val_loss: 0.3376\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2720 - val_loss: 0.3337\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.2700 - val_loss: 0.3299\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 518us/step - loss: 0.2699 - val_loss: 0.3328\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2714 - val_loss: 0.3296\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2703 - val_loss: 0.3409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.2677 - val_loss: 0.3246\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.2674 - val_loss: 0.3310\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.2669 - val_loss: 0.3334\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.2684 - val_loss: 0.3238\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.2634 - val_loss: 0.3375\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2675 - val_loss: 0.3296\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.2634 - val_loss: 0.3464\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.2644 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2673 - val_loss: 0.3359\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.2706 - val_loss: 0.3274\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2644 - val_loss: 0.3254\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.2621 - val_loss: 0.3234\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2610 - val_loss: 0.3329\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2609 - val_loss: 0.3273\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.2591 - val_loss: 0.3466\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.2587 - val_loss: 0.3236\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.2606 - val_loss: 0.3349\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.2582 - val_loss: 0.3431\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.2588 - val_loss: 0.3338\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.2591 - val_loss: 0.3174\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.2578 - val_loss: 0.3340\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.2586 - val_loss: 0.3222\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2543 - val_loss: 0.3209\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.2538 - val_loss: 0.3293\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.2550 - val_loss: 0.3285\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.2567 - val_loss: 0.3251\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.2521 - val_loss: 0.3328\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.2533 - val_loss: 0.3314\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.2535 - val_loss: 0.3193\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.2526 - val_loss: 0.3574\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.2511 - val_loss: 0.3195\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.2508 - val_loss: 0.3237\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2529 - val_loss: 0.3412\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2490 - val_loss: 0.3253\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2519 - val_loss: 0.3196\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2508 - val_loss: 0.3297\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2493 - val_loss: 0.3242\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2478 - val_loss: 0.3209\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.2487 - val_loss: 0.3280\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2481 - val_loss: 0.3233\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.2492 - val_loss: 0.3249\n",
      "121/121 [==============================] - 0s 291us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.9802 - val_loss: 0.6437\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6717 - val_loss: 0.5990\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.4968 - val_loss: 0.4713\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.4400 - val_loss: 0.4439\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4212 - val_loss: 0.4287\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4083 - val_loss: 0.4235\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3985 - val_loss: 0.4115\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.3903 - val_loss: 0.4074\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3818 - val_loss: 0.4056\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3745 - val_loss: 0.4053\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3709 - val_loss: 0.3991\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3659 - val_loss: 0.3929\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3586 - val_loss: 0.3854\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.3547 - val_loss: 0.3828\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3500 - val_loss: 0.3865\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3440 - val_loss: 0.3753\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3413 - val_loss: 0.3760\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3339 - val_loss: 0.3669\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3337 - val_loss: 0.3597\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3304 - val_loss: 0.3618\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.3264 - val_loss: 0.3675\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3224 - val_loss: 0.3534\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.3219 - val_loss: 0.3572\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.3184 - val_loss: 0.3610\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.3139 - val_loss: 0.3582\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3146 - val_loss: 0.3444\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3119 - val_loss: 0.3702\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3119 - val_loss: 0.3418\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3073 - val_loss: 0.3402\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.3057 - val_loss: 0.3431\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3074 - val_loss: 0.3376\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.3062 - val_loss: 0.3399\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3004 - val_loss: 0.3382\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.2998 - val_loss: 0.3391\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 509us/step - loss: 0.2984 - val_loss: 0.3579\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3007 - val_loss: 0.3325\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.2945 - val_loss: 0.3849\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.2963 - val_loss: 0.3300\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.2945 - val_loss: 0.3455\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.2955 - val_loss: 0.3324\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.2909 - val_loss: 0.3293\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2937 - val_loss: 0.3720\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.2930 - val_loss: 0.3448\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.2913 - val_loss: 0.3397\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.2928 - val_loss: 0.3300\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.2923 - val_loss: 0.3287\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.2895 - val_loss: 0.3357\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.2883 - val_loss: 0.3398\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.2852 - val_loss: 0.3241\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.2841 - val_loss: 0.3229\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.2816 - val_loss: 0.3260\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.2823 - val_loss: 0.3269\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.2803 - val_loss: 0.3259\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2797 - val_loss: 0.3354\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.2784 - val_loss: 0.3314\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.2779 - val_loss: 0.3325\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.2765 - val_loss: 0.3258\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.2805 - val_loss: 0.3244\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2765 - val_loss: 0.3407\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2749 - val_loss: 0.3392\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2772 - val_loss: 0.3267\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2732 - val_loss: 0.3280\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2750 - val_loss: 0.3308\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2740 - val_loss: 0.3364\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.2722 - val_loss: 0.3418\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.2719 - val_loss: 0.3257\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.2706 - val_loss: 0.3331\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.2726 - val_loss: 0.3268\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.2708 - val_loss: 0.3286\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.2705 - val_loss: 0.3353\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2713 - val_loss: 0.3240\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2715 - val_loss: 0.3801\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2711 - val_loss: 0.3207\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.2681 - val_loss: 0.3227\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2679 - val_loss: 0.3283\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2680 - val_loss: 0.3219\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.2658 - val_loss: 0.3302\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.2675 - val_loss: 0.3313\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.2666 - val_loss: 0.3148\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.2617 - val_loss: 0.3371\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.2635 - val_loss: 0.3220\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.2609 - val_loss: 0.3376\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.2604 - val_loss: 0.3225\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.2613 - val_loss: 0.3276\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.2626 - val_loss: 0.3186\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.2605 - val_loss: 0.3312\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2609 - val_loss: 0.3223\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.2595 - val_loss: 0.3170\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.2596 - val_loss: 0.3460\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.2614 - val_loss: 0.3181\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.2596 - val_loss: 0.3345\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.2612 - val_loss: 0.3363\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2607 - val_loss: 0.3245\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.2610 - val_loss: 0.3150\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2565 - val_loss: 0.3195\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.2554 - val_loss: 0.3262\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.2538 - val_loss: 0.3167\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.2539 - val_loss: 0.3221\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.2542 - val_loss: 0.3150\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.2547 - val_loss: 0.3145\n",
      "121/121 [==============================] - 0s 287us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 1.2006 - val_loss: 0.6956\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.6417 - val_loss: 0.6186\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5875 - val_loss: 0.5768\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5464 - val_loss: 0.5480\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.5167 - val_loss: 0.5221\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4944 - val_loss: 0.5014\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4776 - val_loss: 0.4887\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.4636 - val_loss: 0.4767\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4551 - val_loss: 0.4690\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4470 - val_loss: 0.4705\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4401 - val_loss: 0.4592\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4351 - val_loss: 0.4531\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 487us/step - loss: 0.4309 - val_loss: 0.4550\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4262 - val_loss: 0.4453\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4223 - val_loss: 0.4474\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4198 - val_loss: 0.4409\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.4160 - val_loss: 0.4380\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4124 - val_loss: 0.4367\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4090 - val_loss: 0.4402\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4067 - val_loss: 0.4304\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4041 - val_loss: 0.4314\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.4006 - val_loss: 0.4304\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3992 - val_loss: 0.4273\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3959 - val_loss: 0.4323\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3952 - val_loss: 0.4233\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3921 - val_loss: 0.4253\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3903 - val_loss: 0.4200\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3876 - val_loss: 0.4192\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3858 - val_loss: 0.4145\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3836 - val_loss: 0.4141\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3818 - val_loss: 0.4131\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3801 - val_loss: 0.4106\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3784 - val_loss: 0.4088\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3762 - val_loss: 0.4088\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3741 - val_loss: 0.4083\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3730 - val_loss: 0.4069\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3708 - val_loss: 0.4032\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3698 - val_loss: 0.4027\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3683 - val_loss: 0.4009\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3662 - val_loss: 0.4004\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3650 - val_loss: 0.3977\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3640 - val_loss: 0.3953\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3626 - val_loss: 0.3946\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3618 - val_loss: 0.3936\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3603 - val_loss: 0.3924\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3586 - val_loss: 0.3939\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3581 - val_loss: 0.3917\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3568 - val_loss: 0.3924\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3556 - val_loss: 0.3875\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3544 - val_loss: 0.3876\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3533 - val_loss: 0.3902\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3522 - val_loss: 0.3867\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3505 - val_loss: 0.3893\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3504 - val_loss: 0.3871\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3491 - val_loss: 0.3873\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3483 - val_loss: 0.3881\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3471 - val_loss: 0.3910\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3466 - val_loss: 0.3841\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3461 - val_loss: 0.3816\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3453 - val_loss: 0.3794\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3435 - val_loss: 0.3804\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3434 - val_loss: 0.3783\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3422 - val_loss: 0.3798\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3418 - val_loss: 0.3846\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3424 - val_loss: 0.3761\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3402 - val_loss: 0.3792\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3398 - val_loss: 0.3780\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3391 - val_loss: 0.3757\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3383 - val_loss: 0.3748\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3368 - val_loss: 0.3740\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3359 - val_loss: 0.3745\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3352 - val_loss: 0.3767\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3350 - val_loss: 0.3757\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3344 - val_loss: 0.3718\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3332 - val_loss: 0.3764\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.3334 - val_loss: 0.3722\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3320 - val_loss: 0.3709\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3312 - val_loss: 0.3746\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3306 - val_loss: 0.3688\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3307 - val_loss: 0.3679\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.3301 - val_loss: 0.3668\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3285 - val_loss: 0.3680\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3279 - val_loss: 0.3713\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3272 - val_loss: 0.3685\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3271 - val_loss: 0.3651\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3263 - val_loss: 0.3638\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3254 - val_loss: 0.3675\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.3257 - val_loss: 0.3623\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3248 - val_loss: 0.3607\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3227 - val_loss: 0.3664\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3225 - val_loss: 0.3685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3227 - val_loss: 0.3640\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3225 - val_loss: 0.3718\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3222 - val_loss: 0.3598\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3210 - val_loss: 0.3642\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3204 - val_loss: 0.3587\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3189 - val_loss: 0.3609\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3201 - val_loss: 0.3582\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3183 - val_loss: 0.3594\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3176 - val_loss: 0.3604\n",
      "121/121 [==============================] - 0s 275us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 1.4282 - val_loss: 0.7080\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.6504 - val_loss: 0.6319\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5772 - val_loss: 0.5871\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5327 - val_loss: 0.5541\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4997 - val_loss: 0.5201\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.4772 - val_loss: 0.5002\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4603 - val_loss: 0.4845\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4461 - val_loss: 0.4737\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4381 - val_loss: 0.4656\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.4300 - val_loss: 0.4583\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4232 - val_loss: 0.4504\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4183 - val_loss: 0.4460\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4135 - val_loss: 0.4421\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4094 - val_loss: 0.4396\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4055 - val_loss: 0.4441\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.4022 - val_loss: 0.4329\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3989 - val_loss: 0.4313\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3954 - val_loss: 0.4288\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3925 - val_loss: 0.4300\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3902 - val_loss: 0.4299\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3880 - val_loss: 0.4224\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3855 - val_loss: 0.4233\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3831 - val_loss: 0.4207\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3803 - val_loss: 0.4220\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3803 - val_loss: 0.4179\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3759 - val_loss: 0.4252\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.3759 - val_loss: 0.4153\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3742 - val_loss: 0.4165\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3721 - val_loss: 0.4141\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3705 - val_loss: 0.4140\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3688 - val_loss: 0.4113\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3679 - val_loss: 0.4102\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3655 - val_loss: 0.4110\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3649 - val_loss: 0.4089\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3631 - val_loss: 0.4086\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3619 - val_loss: 0.4069\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3591 - val_loss: 0.4074\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3589 - val_loss: 0.4054\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3578 - val_loss: 0.4043\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3561 - val_loss: 0.4027\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3540 - val_loss: 0.4053\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3533 - val_loss: 0.4030\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3530 - val_loss: 0.4016\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3523 - val_loss: 0.4019\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3508 - val_loss: 0.4014\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3496 - val_loss: 0.3993\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3489 - val_loss: 0.4027\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3476 - val_loss: 0.3996\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3466 - val_loss: 0.3984\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3454 - val_loss: 0.3977\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3455 - val_loss: 0.3998\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3445 - val_loss: 0.3974\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3426 - val_loss: 0.3972\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3435 - val_loss: 0.4016\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3415 - val_loss: 0.3956\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3396 - val_loss: 0.3962\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3400 - val_loss: 0.3962\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3385 - val_loss: 0.3987\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3378 - val_loss: 0.3919\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3369 - val_loss: 0.3927\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3365 - val_loss: 0.3927\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3352 - val_loss: 0.3939\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3365 - val_loss: 0.3921\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3331 - val_loss: 0.3973\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3350 - val_loss: 0.3901\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3321 - val_loss: 0.3905\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3320 - val_loss: 0.3889\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3332 - val_loss: 0.3901\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3307 - val_loss: 0.3891\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 477us/step - loss: 0.3317 - val_loss: 0.3868\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3292 - val_loss: 0.3864\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3284 - val_loss: 0.3875\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3280 - val_loss: 0.3865\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3270 - val_loss: 0.3841\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3272 - val_loss: 0.3864\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3266 - val_loss: 0.3858\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3250 - val_loss: 0.3854\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3244 - val_loss: 0.3843\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3236 - val_loss: 0.3823\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3250 - val_loss: 0.3868\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3226 - val_loss: 0.3825\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3221 - val_loss: 0.3834\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3212 - val_loss: 0.3837\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3202 - val_loss: 0.3839\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3216 - val_loss: 0.3820\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3198 - val_loss: 0.3832\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.3233 - val_loss: 0.3837\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3181 - val_loss: 0.3801\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3166 - val_loss: 0.3790\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3181 - val_loss: 0.3798\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3155 - val_loss: 0.3824\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3159 - val_loss: 0.3835\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3142 - val_loss: 0.3813\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3156 - val_loss: 0.3782\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3143 - val_loss: 0.3753\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3132 - val_loss: 0.3777\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3121 - val_loss: 0.3745\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3146 - val_loss: 0.3788\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3111 - val_loss: 0.3766\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.3104 - val_loss: 0.3786\n",
      "121/121 [==============================] - 0s 271us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 653us/step - loss: 1.3137 - val_loss: 0.7702\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.8521 - val_loss: 0.6404\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6239 - val_loss: 0.5768\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.5504 - val_loss: 0.5364\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5111 - val_loss: 0.5093\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.4846 - val_loss: 0.4866\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4660 - val_loss: 0.4815\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4544 - val_loss: 0.4688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4451 - val_loss: 0.4624\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4373 - val_loss: 0.4563\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4324 - val_loss: 0.4513\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4276 - val_loss: 0.4481\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4225 - val_loss: 0.4443\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4190 - val_loss: 0.4443\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4150 - val_loss: 0.4435\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4115 - val_loss: 0.4394\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4088 - val_loss: 0.4354\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.4050 - val_loss: 0.4343\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.4030 - val_loss: 0.4302\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4001 - val_loss: 0.4349\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3979 - val_loss: 0.4296\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3956 - val_loss: 0.4297\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3930 - val_loss: 0.4255\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.3910 - val_loss: 0.4320\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3890 - val_loss: 0.4236\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3876 - val_loss: 0.4230\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3854 - val_loss: 0.4222\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3839 - val_loss: 0.4195\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3819 - val_loss: 0.4196\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3800 - val_loss: 0.4170\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3791 - val_loss: 0.4130\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3774 - val_loss: 0.4136\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3749 - val_loss: 0.4152\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3745 - val_loss: 0.4114\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.3731 - val_loss: 0.4093\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3711 - val_loss: 0.4081\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3697 - val_loss: 0.4123\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3683 - val_loss: 0.4070\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3671 - val_loss: 0.4063\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3662 - val_loss: 0.4027\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3639 - val_loss: 0.4072\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3636 - val_loss: 0.4039\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3631 - val_loss: 0.4033\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3606 - val_loss: 0.4066\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3605 - val_loss: 0.3977\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3593 - val_loss: 0.4001\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3578 - val_loss: 0.4012\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 473us/step - loss: 0.3567 - val_loss: 0.3987\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3556 - val_loss: 0.3976\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3548 - val_loss: 0.3962\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3529 - val_loss: 0.3950\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3525 - val_loss: 0.3944\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3512 - val_loss: 0.3929\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3502 - val_loss: 0.3920\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3491 - val_loss: 0.3940\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3484 - val_loss: 0.3932\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3466 - val_loss: 0.3936\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3466 - val_loss: 0.3888\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.3457 - val_loss: 0.3888\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3448 - val_loss: 0.3875\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3436 - val_loss: 0.3870\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3423 - val_loss: 0.3884\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.3421 - val_loss: 0.3894\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3413 - val_loss: 0.3884\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3400 - val_loss: 0.3875\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3403 - val_loss: 0.3844\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3389 - val_loss: 0.3836\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3385 - val_loss: 0.3876\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3376 - val_loss: 0.3838\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3367 - val_loss: 0.3813\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3362 - val_loss: 0.3798\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3355 - val_loss: 0.3823\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3351 - val_loss: 0.3784\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3338 - val_loss: 0.3771\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3335 - val_loss: 0.3810\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3331 - val_loss: 0.3774\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3324 - val_loss: 0.3787\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3307 - val_loss: 0.3854\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3303 - val_loss: 0.3760\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3294 - val_loss: 0.3755\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3290 - val_loss: 0.3774\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3285 - val_loss: 0.3767\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3272 - val_loss: 0.3789\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3278 - val_loss: 0.3741\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3272 - val_loss: 0.3744\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3256 - val_loss: 0.3795\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3250 - val_loss: 0.3722\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3243 - val_loss: 0.3724\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3239 - val_loss: 0.3788\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3241 - val_loss: 0.3733\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3228 - val_loss: 0.3724\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3222 - val_loss: 0.3752\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3217 - val_loss: 0.3723\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3215 - val_loss: 0.3687\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3205 - val_loss: 0.3666\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3199 - val_loss: 0.3685\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3186 - val_loss: 0.3684\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3192 - val_loss: 0.3664\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3184 - val_loss: 0.3656\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3176 - val_loss: 0.3707\n",
      "121/121 [==============================] - 0s 263us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 584us/step - loss: 1.0152 - val_loss: 0.5622\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5335 - val_loss: 0.5426\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5459 - val_loss: 0.5547\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5273 - val_loss: 0.5532\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5301 - val_loss: 0.5612\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5360 - val_loss: 0.5444\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5359 - val_loss: 0.5536\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5220 - val_loss: 0.5359\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5298 - val_loss: 0.5444\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5354 - val_loss: 0.5487\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5267 - val_loss: 0.5497\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5247 - val_loss: 0.5428\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5473 - val_loss: 0.5620\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5278 - val_loss: 0.5359\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5279 - val_loss: 0.6065\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5360 - val_loss: 0.5416\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5248 - val_loss: 0.5366\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5248 - val_loss: 0.5575\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5290 - val_loss: 0.5771\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5251 - val_loss: 0.5689\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.5515 - val_loss: 0.5632\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5251 - val_loss: 0.5861\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5307 - val_loss: 0.5636\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.5265 - val_loss: 0.5703\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.5289 - val_loss: 0.5496\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 458us/step - loss: 0.5296 - val_loss: 0.5431\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5318 - val_loss: 0.5391\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.5269 - val_loss: 0.5529\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5374 - val_loss: 0.5468\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5408 - val_loss: 0.5418\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.5261 - val_loss: 0.5525\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5354 - val_loss: 0.5390\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5292 - val_loss: 0.5458\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5272 - val_loss: 0.5638\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5310 - val_loss: 0.5414\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5248 - val_loss: 0.5764\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5286 - val_loss: 0.5560\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5301 - val_loss: 0.5537\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5224 - val_loss: 0.5571\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5302 - val_loss: 0.5389\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5223 - val_loss: 0.5400\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5357 - val_loss: 0.5488\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5242 - val_loss: 0.5371\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5296 - val_loss: 0.5812\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5213 - val_loss: 0.5477\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5310 - val_loss: 0.5770\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5346 - val_loss: 0.5385\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5275 - val_loss: 0.5766\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5283 - val_loss: 0.5528\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5395 - val_loss: 0.5537\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5252 - val_loss: 0.5686\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5271 - val_loss: 0.5428\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5396 - val_loss: 0.5797\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5334 - val_loss: 0.5356\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5265 - val_loss: 0.5410\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5256 - val_loss: 0.5619\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5343 - val_loss: 0.5456\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5295 - val_loss: 0.5935\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5336 - val_loss: 0.5522\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5316 - val_loss: 0.5532\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5262 - val_loss: 0.5416\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5245 - val_loss: 0.5911\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5311 - val_loss: 0.5526\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5279 - val_loss: 0.5868\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5297 - val_loss: 0.5440\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5271 - val_loss: 0.5638\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5474 - val_loss: 0.7045\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5295 - val_loss: 0.5480\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5345 - val_loss: 0.5732\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.5388 - val_loss: 0.5589\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5342 - val_loss: 0.5412\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5220 - val_loss: 0.5443\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5340 - val_loss: 0.5548\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5278 - val_loss: 0.5494\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5288 - val_loss: 0.5407\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5293 - val_loss: 0.5520\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5375 - val_loss: 0.5489\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5244 - val_loss: 0.6732\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5400 - val_loss: 0.5753\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5367 - val_loss: 0.5414\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5281 - val_loss: 0.5550\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5310 - val_loss: 0.5380\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5323 - val_loss: 0.5422\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.5279 - val_loss: 0.5582\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5271 - val_loss: 0.5389\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5368 - val_loss: 0.5412\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5259 - val_loss: 0.5423\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5317 - val_loss: 0.5424\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5320 - val_loss: 0.5652\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5323 - val_loss: 0.5446\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5268 - val_loss: 0.5724\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5264 - val_loss: 0.5494\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5370 - val_loss: 0.8222\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5297 - val_loss: 0.5498\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5328 - val_loss: 0.5456\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5246 - val_loss: 0.5564\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5325 - val_loss: 0.5826\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5313 - val_loss: 0.5564\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5324 - val_loss: 0.5508\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5286 - val_loss: 0.5566\n",
      "121/121 [==============================] - 0s 250us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 1.0419 - val_loss: 1.0607\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.9753 - val_loss: 16.2874\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 740.6517 - val_loss: 464.5461\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 425us/step - loss: 4266.4810 - val_loss: 15374.7832\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 234486.8281 - val_loss: 513228.2812\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 523519.8125 - val_loss: 16968456.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 15591908.0000 - val_loss: 559842432.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 14062781440.0000 - val_loss: 17497174016.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 178891505664.0000 - val_loss: 592606658560.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 6123171086336.0000 - val_loss: 20131222650880.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 968076367495168.0000 - val_loss: 641385719922688.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 32801414711345152.0000 - val_loss: 20819347161219072.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 308865391906521088.0000 - val_loss: 699385258935582720.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 17435036145992859648.0000 - val_loss: 21415724535867506688.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 312332339535631351808.0000 - val_loss: 708768416949988229120.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 10905177141401597509632.0000 - val_loss: 24166693902838780657664.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 221258354899401628975104.0000 - val_loss: 829990929355042579283968.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 941762634001410269642752.0000 - val_loss: 23252418358659078378487808.0000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 18901820638321947826978816.0000 - val_loss: 800591053982235974957006848.0000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 8263447747444707644827238400.0000 - val_loss: 27484125706636506447258583040.0000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 1309402213450167686503002537984.0000 - val_loss: 832089587878096240886104981504.0000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 904857477485931177912989384704.0000 - val_loss: 26947444925241208614387244335104.0000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 395810321266458719102455276109824.0000 - val_loss: 917193953154170833831188922105856.0000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 21997837971369893295438266512703488.0000 - val_loss: 32338123338553446221700069716918272.0000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: inf - val_loss: inf            \n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: inf - val_loss: inf               \n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: inf - val_loss: inf              \n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: inf - val_loss: inf\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: inf - val_loss: inf\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: inf - val_loss: inf\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: inf - val_loss: inf\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: inf - val_loss: inf\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: inf - val_loss: inf\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: inf - val_loss: inf\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: inf - val_loss: inf\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: inf - val_loss: inf\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: inf - val_loss: inf\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: inf - val_loss: inf\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: inf - val_loss: inf\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: inf - val_loss: inf\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: inf - val_loss: inf\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: inf - val_loss: inf\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: inf - val_loss: inf\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: inf - val_loss: inf\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: inf - val_loss: inf\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: inf - val_loss: inf\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: inf - val_loss: inf\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 347us/step\n",
      "Epoch 1/100\n",
      "165/242 [===================>..........] - ETA: 0s - loss: 1.1137 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/scikeras/wrappers.py\", line 1120, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/scikeras/wrappers.py\", line 1717, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 607us/step - loss: 0.9302 - val_loss: 0.8205\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 1.2901 - val_loss: 40.5764\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 113.2854 - val_loss: 4117.2905\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 10056.2314 - val_loss: 437651.2188\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 1247738.1250 - val_loss: 46376540.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 92798584.0000 - val_loss: 4978811392.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 10817931264.0000 - val_loss: 524563447808.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 1845197930496.0000 - val_loss: 55584825016320.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 159213934346240.0000 - val_loss: 5894965557198848.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 18124579453009920.0000 - val_loss: 625184854174072832.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 2142592882840698880.0000 - val_loss: 66208416478531682304.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 229059427827225460736.0000 - val_loss: 7019978037864412741632.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 21016236812308769144832.0000 - val_loss: 744413024832590148796416.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 2534110226141179736489984.0000 - val_loss: 78858834790928352842612736.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 205778078721736623083487232.0000 - val_loss: 8364867060918247221553528832.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 23689966328990545783363207168.0000 - val_loss: 923564773407966579334009847808.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 2171442787393488913363806191616.0000 - val_loss: 98148460889846369950799656648704.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 253664185083337864216298857168896.0000 - val_loss: 10394394488360677612697369024921600.0000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 20451554302979389072427818225238016.0000 - val_loss: inf\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: inf - val_loss: inf             \n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: inf - val_loss: inf              \n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: inf - val_loss: inf\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: inf - val_loss: inf\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: inf - val_loss: inf\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: inf - val_loss: inf\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: inf - val_loss: inf\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: inf - val_loss: inf\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: inf - val_loss: inf\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: inf - val_loss: inf\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: inf - val_loss: inf\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: inf - val_loss: inf\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: inf - val_loss: inf\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: inf - val_loss: inf\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: inf - val_loss: inf\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: inf - val_loss: inf\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: inf - val_loss: inf\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 252us/step\n",
      "Epoch 1/100\n",
      "154/242 [==================>...........] - ETA: 0s - loss: 6.1884 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/scikeras/wrappers.py\", line 1120, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/scikeras/wrappers.py\", line 1717, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 661us/step - loss: 5.7404 - val_loss: 4.8116\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 4.0569 - val_loss: 3.5628\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 3.1083 - val_loss: 2.7830\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 2.4767 - val_loss: 2.2455\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 2.0341 - val_loss: 1.8699\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 1.7232 - val_loss: 1.6086\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 1.5058 - val_loss: 1.4274\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 1.3530 - val_loss: 1.2993\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 1.2436 - val_loss: 1.2062\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 1.1609 - val_loss: 1.1333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 1.0933 - val_loss: 1.0720\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 1.0342 - val_loss: 1.0174\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.9801 - val_loss: 0.9671\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.9295 - val_loss: 0.9201\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.8826 - val_loss: 0.8766\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.8394 - val_loss: 0.8374\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.8008 - val_loss: 0.8029\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.7671 - val_loss: 0.7731\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.7382 - val_loss: 0.7480\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.7142 - val_loss: 0.7271\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.6942 - val_loss: 0.7100\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6777 - val_loss: 0.6959\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.6640 - val_loss: 0.6843\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.6526 - val_loss: 0.6746\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.6430 - val_loss: 0.6662\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.6348 - val_loss: 0.6589\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.6277 - val_loss: 0.6523\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.6214 - val_loss: 0.6464\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.6156 - val_loss: 0.6411\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.6104 - val_loss: 0.6361\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.6055 - val_loss: 0.6314\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.6010 - val_loss: 0.6270\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5968 - val_loss: 0.6229\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5927 - val_loss: 0.6189\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5889 - val_loss: 0.6153\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5851 - val_loss: 0.6117\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5815 - val_loss: 0.6083\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5780 - val_loss: 0.6050\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5746 - val_loss: 0.6016\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.5714 - val_loss: 0.5984\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5682 - val_loss: 0.5953\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5652 - val_loss: 0.5923\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5623 - val_loss: 0.5894\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5595 - val_loss: 0.5866\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5568 - val_loss: 0.5838\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5542 - val_loss: 0.5812\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5516 - val_loss: 0.5787\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5491 - val_loss: 0.5762\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5467 - val_loss: 0.5738\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5443 - val_loss: 0.5714\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5420 - val_loss: 0.5690\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5399 - val_loss: 0.5668\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5378 - val_loss: 0.5647\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5357 - val_loss: 0.5627\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5337 - val_loss: 0.5607\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5317 - val_loss: 0.5587\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5299 - val_loss: 0.5568\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5280 - val_loss: 0.5549\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5263 - val_loss: 0.5532\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5246 - val_loss: 0.5514\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5229 - val_loss: 0.5497\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5213 - val_loss: 0.5480\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5197 - val_loss: 0.5463\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5181 - val_loss: 0.5445\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5165 - val_loss: 0.5429\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5149 - val_loss: 0.5414\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5134 - val_loss: 0.5398\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5119 - val_loss: 0.5383\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5104 - val_loss: 0.5367\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5090 - val_loss: 0.5352\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5076 - val_loss: 0.5337\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5061 - val_loss: 0.5323\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5048 - val_loss: 0.5309\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5034 - val_loss: 0.5296\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5020 - val_loss: 0.5282\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5007 - val_loss: 0.5268\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4995 - val_loss: 0.5255\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4982 - val_loss: 0.5242\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4969 - val_loss: 0.5229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4957 - val_loss: 0.5217\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4945 - val_loss: 0.5205\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4933 - val_loss: 0.5193\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4922 - val_loss: 0.5182\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4911 - val_loss: 0.5170\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4900 - val_loss: 0.5159\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4890 - val_loss: 0.5149\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4879 - val_loss: 0.5138\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4869 - val_loss: 0.5128\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4860 - val_loss: 0.5118\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4850 - val_loss: 0.5109\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4841 - val_loss: 0.5100\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4831 - val_loss: 0.5090\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4822 - val_loss: 0.5081\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4813 - val_loss: 0.5072\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4804 - val_loss: 0.5063\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4795 - val_loss: 0.5054\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4787 - val_loss: 0.5046\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4778 - val_loss: 0.5038\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4770 - val_loss: 0.5029\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4762 - val_loss: 0.5021\n",
      "121/121 [==============================] - 0s 270us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 4.0896 - val_loss: 2.9746\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 2.2750 - val_loss: 1.7631\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 1.4133 - val_loss: 1.1872\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 1.0474 - val_loss: 0.9736\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.9013 - val_loss: 0.8804\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.8290 - val_loss: 0.8285\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.7803 - val_loss: 0.7856\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.7411 - val_loss: 0.7527\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.7130 - val_loss: 0.7276\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.6884 - val_loss: 0.7075\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.6672 - val_loss: 0.6919\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.6520 - val_loss: 0.6795\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.6394 - val_loss: 0.6699\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.6289 - val_loss: 0.6623\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.6209 - val_loss: 0.6556\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.6139 - val_loss: 0.6497\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.6078 - val_loss: 0.6441\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.6021 - val_loss: 0.6390\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5969 - val_loss: 0.6343\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5920 - val_loss: 0.6294\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5873 - val_loss: 0.6251\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5828 - val_loss: 0.6200\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5785 - val_loss: 0.6160\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5744 - val_loss: 0.6113\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5705 - val_loss: 0.6071\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5666 - val_loss: 0.6029\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5628 - val_loss: 0.5991\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5592 - val_loss: 0.5947\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5557 - val_loss: 0.5914\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5524 - val_loss: 0.5874\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5491 - val_loss: 0.5841\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5460 - val_loss: 0.5804\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5429 - val_loss: 0.5773\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5401 - val_loss: 0.5739\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5372 - val_loss: 0.5709\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5345 - val_loss: 0.5675\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5319 - val_loss: 0.5651\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5294 - val_loss: 0.5623\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5270 - val_loss: 0.5590\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5248 - val_loss: 0.5565\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5225 - val_loss: 0.5543\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5203 - val_loss: 0.5522\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5182 - val_loss: 0.5496\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5162 - val_loss: 0.5475\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5142 - val_loss: 0.5451\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5123 - val_loss: 0.5431\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5103 - val_loss: 0.5414\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5086 - val_loss: 0.5392\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5067 - val_loss: 0.5370\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5051 - val_loss: 0.5355\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5034 - val_loss: 0.5336\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5018 - val_loss: 0.5318\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5002 - val_loss: 0.5303\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4987 - val_loss: 0.5291\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4972 - val_loss: 0.5273\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4957 - val_loss: 0.5255\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4944 - val_loss: 0.5243\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 445us/step - loss: 0.4929 - val_loss: 0.5228\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4916 - val_loss: 0.5215\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4903 - val_loss: 0.5199\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4890 - val_loss: 0.5185\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4877 - val_loss: 0.5179\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4865 - val_loss: 0.5160\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4853 - val_loss: 0.5150\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4841 - val_loss: 0.5139\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4830 - val_loss: 0.5123\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4818 - val_loss: 0.5115\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4807 - val_loss: 0.5100\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4796 - val_loss: 0.5091\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.4786 - val_loss: 0.5078\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4775 - val_loss: 0.5067\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4764 - val_loss: 0.5056\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4754 - val_loss: 0.5046\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4744 - val_loss: 0.5038\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4733 - val_loss: 0.5025\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4723 - val_loss: 0.5015\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4714 - val_loss: 0.5007\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4704 - val_loss: 0.4996\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4695 - val_loss: 0.4989\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4686 - val_loss: 0.4979\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4677 - val_loss: 0.4971\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4668 - val_loss: 0.4962\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4660 - val_loss: 0.4954\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4651 - val_loss: 0.4946\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4643 - val_loss: 0.4935\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4634 - val_loss: 0.4928\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4625 - val_loss: 0.4922\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4617 - val_loss: 0.4914\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4609 - val_loss: 0.4904\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4601 - val_loss: 0.4897\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.4592 - val_loss: 0.4891\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4585 - val_loss: 0.4880\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4576 - val_loss: 0.4874\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4569 - val_loss: 0.4864\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4562 - val_loss: 0.4858\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4554 - val_loss: 0.4849\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4547 - val_loss: 0.4844\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.4539 - val_loss: 0.4841\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4532 - val_loss: 0.4831\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4524 - val_loss: 0.4827\n",
      "121/121 [==============================] - 0s 280us/step\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 5.1513 - val_loss: 3.4460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 2.8235 - val_loss: 2.2611\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 1.9404 - val_loss: 1.6474\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 1.4763 - val_loss: 1.3048\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 1.2063 - val_loss: 1.0989\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 1.0393 - val_loss: 0.9724\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.9339 - val_loss: 0.8929\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.8652 - val_loss: 0.8398\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.8198 - val_loss: 0.8052\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.7884 - val_loss: 0.7793\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.7657 - val_loss: 0.7590\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.7479 - val_loss: 0.7425\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.7336 - val_loss: 0.7284\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.7213 - val_loss: 0.7167\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.7102 - val_loss: 0.7055\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.7001 - val_loss: 0.6970\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.6905 - val_loss: 0.6864\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.6811 - val_loss: 0.6778\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.6723 - val_loss: 0.6685\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.6638 - val_loss: 0.6620\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.6558 - val_loss: 0.6534\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.6479 - val_loss: 0.6467\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.6406 - val_loss: 0.6388\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.6334 - val_loss: 0.6333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.6267 - val_loss: 0.6266\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.6203 - val_loss: 0.6202\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.6140 - val_loss: 0.6146\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.6080 - val_loss: 0.6090\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.6024 - val_loss: 0.6034\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5969 - val_loss: 0.5982\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5917 - val_loss: 0.5936\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5870 - val_loss: 0.5895\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5823 - val_loss: 0.5849\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5781 - val_loss: 0.5806\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5737 - val_loss: 0.5767\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 453us/step - loss: 0.5696 - val_loss: 0.5724\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5659 - val_loss: 0.5697\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5622 - val_loss: 0.5667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5588 - val_loss: 0.5632\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5555 - val_loss: 0.5592\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.5522 - val_loss: 0.5565\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5488 - val_loss: 0.5547\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5462 - val_loss: 0.5508\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5430 - val_loss: 0.5481\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5401 - val_loss: 0.5468\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.5375 - val_loss: 0.5435\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5350 - val_loss: 0.5418\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5324 - val_loss: 0.5394\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.5300 - val_loss: 0.5374\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5279 - val_loss: 0.5352\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5256 - val_loss: 0.5332\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.5234 - val_loss: 0.5314\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.5211 - val_loss: 0.5302\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5196 - val_loss: 0.5277\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5173 - val_loss: 0.5261\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5153 - val_loss: 0.5247\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5136 - val_loss: 0.5226\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5119 - val_loss: 0.5212\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.5102 - val_loss: 0.5198\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5084 - val_loss: 0.5184\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5068 - val_loss: 0.5169\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5051 - val_loss: 0.5164\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5037 - val_loss: 0.5147\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5022 - val_loss: 0.5130\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5007 - val_loss: 0.5117\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4993 - val_loss: 0.5104\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4980 - val_loss: 0.5092\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4967 - val_loss: 0.5081\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4954 - val_loss: 0.5070\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4942 - val_loss: 0.5055\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4929 - val_loss: 0.5048\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4917 - val_loss: 0.5040\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4906 - val_loss: 0.5031\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4894 - val_loss: 0.5022\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4883 - val_loss: 0.5012\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4872 - val_loss: 0.5006\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4863 - val_loss: 0.4991\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4852 - val_loss: 0.4987\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4841 - val_loss: 0.4982\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4833 - val_loss: 0.4975\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4825 - val_loss: 0.4962\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4816 - val_loss: 0.4953\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4804 - val_loss: 0.4945\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4799 - val_loss: 0.4938\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4790 - val_loss: 0.4928\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4781 - val_loss: 0.4924\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4775 - val_loss: 0.4912\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4766 - val_loss: 0.4902\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4758 - val_loss: 0.4897\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4753 - val_loss: 0.4886\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4746 - val_loss: 0.4877\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4738 - val_loss: 0.4870\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4732 - val_loss: 0.4860\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4726 - val_loss: 0.4853\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4719 - val_loss: 0.4848\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4714 - val_loss: 0.4841\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4709 - val_loss: 0.4834\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4703 - val_loss: 0.4827\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4698 - val_loss: 0.4820\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4690 - val_loss: 0.4814\n",
      "121/121 [==============================] - 0s 263us/step\n",
      "Epoch 1/100\n",
      "138/363 [==========>...................] - ETA: 0s - loss: 1.2997 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desparza/miniconda3/envs/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.76679902 0.41612827 0.72817234 0.76983736 0.66567194 0.76972786\n",
      " 0.77844174 0.74730468        nan 0.64726137]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 582us/step - loss: 0.8353 - val_loss: 0.5122\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.4680 - val_loss: 0.4548\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4224 - val_loss: 0.4264\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4007 - val_loss: 0.4178\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3874 - val_loss: 0.4031\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.3771 - val_loss: 0.3985\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3691 - val_loss: 0.3899\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3603 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3542 - val_loss: 0.3839\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3505 - val_loss: 0.3832\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3447 - val_loss: 0.3728\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3407 - val_loss: 0.3749\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3371 - val_loss: 0.3779\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.3326 - val_loss: 0.3642\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.3293 - val_loss: 0.3810\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3251 - val_loss: 0.3543\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.3262 - val_loss: 0.3567\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3183 - val_loss: 0.3516\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.3187 - val_loss: 0.3521\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.3147 - val_loss: 0.3477\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.3132 - val_loss: 0.3425\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3105 - val_loss: 0.3468\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3078 - val_loss: 0.3558\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3074 - val_loss: 0.3444\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3048 - val_loss: 0.3384\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 482us/step - loss: 0.3015 - val_loss: 0.3388\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.3016 - val_loss: 0.3674\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2993 - val_loss: 0.3599\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.2986 - val_loss: 0.3337\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2958 - val_loss: 0.3444\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2942 - val_loss: 0.3406\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2937 - val_loss: 0.3254\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2925 - val_loss: 0.3263\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2905 - val_loss: 0.3222\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2859 - val_loss: 0.3299\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2884 - val_loss: 0.3340\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2860 - val_loss: 0.3317\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2851 - val_loss: 0.3241\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 463us/step - loss: 0.2836 - val_loss: 0.3367\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.2833 - val_loss: 0.3278\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2823 - val_loss: 0.3220\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2803 - val_loss: 0.3264\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2795 - val_loss: 0.3413\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2787 - val_loss: 0.3214\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2790 - val_loss: 0.3314\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2792 - val_loss: 0.3189\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.2763 - val_loss: 0.3235\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2751 - val_loss: 0.3285\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2745 - val_loss: 0.3168\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.2735 - val_loss: 0.3329\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 465us/step - loss: 0.2728 - val_loss: 0.3100\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.2734 - val_loss: 0.3111\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.2735 - val_loss: 0.3127\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2711 - val_loss: 0.3205\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.2702 - val_loss: 0.3136\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2695 - val_loss: 0.3140\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2681 - val_loss: 0.3174\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2683 - val_loss: 0.3135\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.2666 - val_loss: 0.3078\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2684 - val_loss: 0.3132\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2656 - val_loss: 0.3137\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2648 - val_loss: 0.3133\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2659 - val_loss: 0.3219\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2643 - val_loss: 0.3126\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2641 - val_loss: 0.3095\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.2625 - val_loss: 0.3144\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 463us/step - loss: 0.2641 - val_loss: 0.3087\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.2613 - val_loss: 0.3132\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 487us/step - loss: 0.2592 - val_loss: 0.3189\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.2616 - val_loss: 0.3150\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2604 - val_loss: 0.3128\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2598 - val_loss: 0.3122\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.2587 - val_loss: 0.3070\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.2587 - val_loss: 0.3132\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 463us/step - loss: 0.2557 - val_loss: 0.3215\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2575 - val_loss: 0.3049\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.2585 - val_loss: 0.3149\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2582 - val_loss: 0.2990\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2555 - val_loss: 0.3145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2539 - val_loss: 0.3061\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.2544 - val_loss: 0.3035\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2552 - val_loss: 0.3148\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2558 - val_loss: 0.3222\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.2539 - val_loss: 0.3025\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2515 - val_loss: 0.3195\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2514 - val_loss: 0.3091\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.2521 - val_loss: 0.3000\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2515 - val_loss: 0.3084\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2504 - val_loss: 0.3093\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 454us/step - loss: 0.2501 - val_loss: 0.2985\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 454us/step - loss: 0.2498 - val_loss: 0.3103\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 454us/step - loss: 0.2499 - val_loss: 0.3071\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.2493 - val_loss: 0.3022\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 454us/step - loss: 0.2485 - val_loss: 0.2988\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.2489 - val_loss: 0.3037\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.2481 - val_loss: 0.3091\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.2482 - val_loss: 0.2975\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2491 - val_loss: 0.3041\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.2482 - val_loss: 0.3056\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.2475 - val_loss: 0.3089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(model=&lt;function build_model at 0x29e8a15e0&gt;),\n",
       "                   param_distributions={&#x27;model__learning_rate&#x27;: [0.023070247095618657,\n",
       "                                                                 0.0018812193571737948,\n",
       "                                                                 0.0008643988194531686,\n",
       "                                                                 0.0013501716206451731,\n",
       "                                                                 0.015229009691375188,\n",
       "                                                                 0.0029716549588189875,\n",
       "                                                                 0.0015332955022550018,\n",
       "                                                                 0.003678250463240318,\n",
       "                                                                 0.0005540904555003274,\n",
       "                                                                 0.00030749627843890...\n",
       "                                                                 0.0023673335357571024,\n",
       "                                                                 0.0007937507190397334,\n",
       "                                                                 0.0011245302398817305,\n",
       "                                                                 0.00592763702089295,\n",
       "                                                                 0.0015637438415165158,\n",
       "                                                                 0.003907188555283265,\n",
       "                                                                 0.002004143286241076,\n",
       "                                                                 0.0006532204398808047,\n",
       "                                                                 0.00042185309062706496,\n",
       "                                                                 0.0008903981425272313, ...],\n",
       "                                        &#x27;model__n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;model__n_neurons&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20, 21,\n",
       "                                                             22, 23, 24, 25, 26,\n",
       "                                                             27, 28, 29, 30, ...]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(model=&lt;function build_model at 0x29e8a15e0&gt;),\n",
       "                   param_distributions={&#x27;model__learning_rate&#x27;: [0.023070247095618657,\n",
       "                                                                 0.0018812193571737948,\n",
       "                                                                 0.0008643988194531686,\n",
       "                                                                 0.0013501716206451731,\n",
       "                                                                 0.015229009691375188,\n",
       "                                                                 0.0029716549588189875,\n",
       "                                                                 0.0015332955022550018,\n",
       "                                                                 0.003678250463240318,\n",
       "                                                                 0.0005540904555003274,\n",
       "                                                                 0.00030749627843890...\n",
       "                                                                 0.0023673335357571024,\n",
       "                                                                 0.0007937507190397334,\n",
       "                                                                 0.0011245302398817305,\n",
       "                                                                 0.00592763702089295,\n",
       "                                                                 0.0015637438415165158,\n",
       "                                                                 0.003907188555283265,\n",
       "                                                                 0.002004143286241076,\n",
       "                                                                 0.0006532204398808047,\n",
       "                                                                 0.00042185309062706496,\n",
       "                                                                 0.0008903981425272313, ...],\n",
       "                                        &#x27;model__n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;model__n_neurons&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20, 21,\n",
       "                                                             22, 23, 24, 25, 26,\n",
       "                                                             27, 28, 29, 30, ...]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function build_model at 0x29e8a15e0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function build_model at 0x29e8a15e0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(model=<function build_model at 0x29e8a15e0>),\n",
       "                   param_distributions={'model__learning_rate': [0.023070247095618657,\n",
       "                                                                 0.0018812193571737948,\n",
       "                                                                 0.0008643988194531686,\n",
       "                                                                 0.0013501716206451731,\n",
       "                                                                 0.015229009691375188,\n",
       "                                                                 0.0029716549588189875,\n",
       "                                                                 0.0015332955022550018,\n",
       "                                                                 0.003678250463240318,\n",
       "                                                                 0.0005540904555003274,\n",
       "                                                                 0.00030749627843890...\n",
       "                                                                 0.0023673335357571024,\n",
       "                                                                 0.0007937507190397334,\n",
       "                                                                 0.0011245302398817305,\n",
       "                                                                 0.00592763702089295,\n",
       "                                                                 0.0015637438415165158,\n",
       "                                                                 0.003907188555283265,\n",
       "                                                                 0.002004143286241076,\n",
       "                                                                 0.0006532204398808047,\n",
       "                                                                 0.00042185309062706496,\n",
       "                                                                 0.0008903981425272313, ...],\n",
       "                                        'model__n_hidden': [0, 1, 2, 3],\n",
       "                                        'model__n_neurons': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20, 21,\n",
       "                                                             22, 23, 24, 25, 26,\n",
       "                                                             27, 28, 29, 30, ...]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bdf1b5",
   "metadata": {},
   "source": [
    "The best set of parameters is given by the `best_params_` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c545e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_neurons': 64,\n",
       " 'model__n_hidden': 3,\n",
       " 'model__learning_rate': 0.007484761545938902}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9e466",
   "metadata": {},
   "source": [
    "The `best_score_` property returns the mean of the score for each training using the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84be54cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784417376041489"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b7995",
   "metadata": {},
   "source": [
    "Now we can use the best score to evaluate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec2df27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 290us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7789109358359112"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64007bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d16e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
